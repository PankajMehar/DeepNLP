 
The development of accurate force fields1‚Äì3  for the efficient simulation of large and small systems 
has been a cornerstone of modern computational chemistry. The popularity of force fields is driven 
by low computational cost relative to more accurate and transferable quantum mechanical (QM) 
methods,  such  as  density  function  theory4  (DFT)  or  post-Hartree-Fock5‚Äì7  methods.  However, 
parametrizing  universal  force  fields--applicable  to  any  chemical  system  in  any  chemical 
environment--has remained an elusive goal due to the restrictive functional form of classical force 
fields.  For  this  reason,  a  ‚Äúzoo‚Äù of  force fields  has  been  developed  over  the last  30  years  with 
applications  in  various  regions  of  chemistry  and  physics,  such  as  materials,  proteins, 
carbohydrates, and small drug-like molecules.8‚Äì11  Drawing the line between where these system-
specific force fields work and where they fail is a difficult task.  
In recent years, machine learning (ML) methods have been successfully applied in many areas of 
chemistry and physics research.12‚Äì19 Specifically, ML approaches for the prediction of interatomic 
potential  energy  surfaces  (referred  to  as  ML  potentials)  have  exhibited  chemical  accuracy 
compared  to  QM  models  at  roughly  the  computational  cost  of  classical  force  fields.20‚Äì31  ML 
potentials promise to bridge the speed vs. accuracy gap between force fields and QM methods. 
Many recent studies rely on a philosophy of parametrization to one chemical system at a time22,26, 
single  component  bulk  systems28,29  or  many  equilibrium  structures,  i.e.  QM7  and  QM9 
datasets32,33.  While  parametrization  to  one  system  at  a  time  can  achieve  high  accuracy  with 
relatively small amounts of QM, it has the downside that one must generate additional QM data 
and  train  a  new  ML  model  for  every  new  chemical  system.  Using  this  approach  in  any  study 
requires  extra  parametrization  time  due  to  the  non-universality  of  the  potentials.  Additionally, 
parametrization  to  only  equilibrium  geometries  does  not  attempt  to  describe  the  range  of 
conformations visited in atomistic simulation. For these reasons, single system and equilibrium 
dataset ML potentials do not aim to build an extensible and transferable (universal) ML potential.  
Our work on the ANAKIN-ME (ANI) method for developing the ANI-1 potential34 is one example 
of a universal ML atomistic potential for organic molecules. The methodology is built upon the 
concept of an atomic environment descriptor first developed by Behler and Parrinello35 and refined 
to perform significantly better on large and diverse datasets of organic molecules. A key aspect of 
the ANI methodology was the focus on dataset diversity, which promotes the learning of low level 
interactions (by utilizing localized descriptors) for better transferability. For training the ANI-1 
model, we calculated over 22 million structural conformations from 57,000 distinct small organic 
molecules using DFT.36 The ANI-1 dataset was built through an exhaustive sampling of molecules 
containing between one and eight C, N, and O atoms from the GDB-11 database, with H atoms 
added  to  saturate  the  configurations.  It  is  based  on  a  philosophy  of  dataset  construction  that 
samples small molecule conformational and configurational space at the same time. The ANI-1 
potential was shown to be chemically accurate for systems of 50 atoms and more, demonstrating 
extensibility  and  transferability  to  much  larger  molecules  than  those  in  the  training  set.  This 
phenomenon, whereby an ML model is trained on small systems (which could be thought of as 
fragments of large systems), then demonstrated to be extensible to large systems has also been 
confirmed in other recent studies.37‚Äì39 Other recent work had success in developing universal ML 
property predictors for organic based chemical systems away from their local minima.30  
When it comes to developing or optimizing ML model training datasets, human intuition currently 
drives the experiment design. The resulting datasets tend to be clustered, sparse, and incomplete; 
recent work finds that people tend to favor inclusion of ‚Äúsuccessful‚Äù experiments and tend to forget 
‚Äúfailed‚Äù  experiments.40  The  comprehensive  incorporation  of  all  data  is  the  strength  of  ML 
approaches to artificial intelligence (AI). With sufficient data, an AI-driven machine can more 
effectively  choose  the  next  step  in  experiments  or  simulations  than  humans,  speeding  up  the 
optimization  of  a  given  dataset,  while  also  reducing  the  overall  amount  of  data  required.  As 
robotics transforms chemical synthesis41, manufacturing, and transportation, constituting a modern 
industrial  revolution,42,43  achieving  the  analogous  revolution  in  computational  methods  will 
require AI and in particular the emulation of scientific intuition, reasoning and decision making. 
Such  an  ambitious  program  will  not  be  accomplished  all  at  once  and  will  instead  require 
incremental progress as AI algorithms are developed.  
In this work we present a fully automated approach of dataset generation for training universal ML 
potentials. It is based on the concept of active learning (AL), which has been successfully applied 
to  develop  single  system  ML  potentials.37,44‚Äì47    We  develop  a  two-component  technique  for 
training  universal  ML  potentials.  The  first  component  is  a  dataset  reduction  algorithm  for 
eliminating redundancy in an existing training set. The second is an active learning algorithm based 
on the query by committee48 (QBC) approach for selecting new training data. For a complete and 
rigorous validation of universal potentials, we also develop the COmprehensive Machine-learning 
Potential  (COMP6)  benchmark  suite  for  organic  and  bio-molecules.  The  COMP6  benchmark 
samples the chemical space (for molecules containing C, H, N, and O) of molecules larger than 
those included in the training set, as well as non-covalent interactions via the S66x8 benchmark49. 
The COMP6 benchmark is publicly available on GitHub [https://github.com/isayev/ASE_ANI].  
Using the active learning scheme, a potential can be trained to the accuracy of ANI-1 using 90% 
less  data,  even  while  sampling  from  smaller  molecules.  After  further  exploration  of  chemical 
space,  our  potential  (dubbed  ANI-1x)  strongly  out-performs  ANI-1,  while  being  trained  on  a 
dataset with only 25% of the size. 
II. METHODS 
In the context of this work, the goal of active learning is to infer an accurate predictor from labeled 
training data. These labeled data are input-output pairs (X, y), where the output y represents the 
correct answer to a question associated with the input X. In the problem of ML potential training, 
the label y may be the ‚Äúyes‚Äù / ‚Äúno‚Äù answer to whether the potential correctly describes a molecule 
X. As part of the active learning process, this question may be answered empirically for a given 
substance.  The  Query  by  Committee  (QBC)  approach  uses  the  disagreement  between  models 
trained to similar data to experimentally infer the correctness of an ensemble‚Äôs prediction. This is 
by the following reasoning: if an ensemble of predictors has a high standard deviation, then some 
models  in  the  ensemble  must  have  a  relatively  high  error  from  the  ground  truth.  Therefore, 
studies 
provided 
selection  of  compounds  that  have  a  high 
standard deviation of ensemble predictions 
in  search  of  chemical  space  can  be 
employed to sample high error regions of 
chemical space automatically, minimizing 
the  need  for  redundant  QM  calculations. 
Several 
empirical 
evidence  that  this  method  of  sampling 
indeed improves the overall fitness of ML 
potentials  for  single  systems.37,50  In  this 
work, we apply this concept in a massive 
search  of  chemical  space  to  develop  a 
superior  training  set  for  universal  ML 
ANI34 potentials. These ANI potentials are 
applicable to organic molecules containing 
C,  H,  N,  and  O.  With  minimal 
modification, the same approach could be 
used for other areas of chemical sciences, 
e.g. materials.  
A. Sample selection via Query by 
Committee 
We show how, in a rigorous statistical way, 
one can obtain a priori information about 
what  new  samples  should  be  included  in 
subsequent generations of an ML potential 
training set. The a priori  information is obtained by the QBC48 algorithm. QBC measures the 
disagreement between students (models) of a committee (ensemble), then the algorithm selects 
new examples where the students disagree by a preset inclusion criterion. Finally, new reference 
data for selected examples are obtained and included in the next committee training iteration. As 
a test of agreement, we choose to include new data point  ùëñ only for test cases which generate a 
value ùúå(cid:3036) greater than an inclusion criterion ùúå(cid:3548), where ùúå(cid:3036) is defined as, 
ùúå(cid:3036) =
ùúé(cid:3036)
(cid:3493)ùëÅ(cid:3036)
1. 
In equation 1, ùúé(cid:3036) is the standard deviation of predictions from an ensemble (see Section IIE for 
details) of ANI potentials and ùëÅ(cid:3036) is the number of atoms in the given test system. The square root 
is applied to ùëÅ(cid:3036) since the potentials are atomistic, and the total energy error is assumed to be a 
random distribution, centered around zero, per atom. That is, cancellation of error on a per atom 
basis can lead to artificially low per atom errors (and standard deviations in this case) on larger 
molecules when a square root is not applied. This is necessary when using a single value of ùúå(cid:3548) to 
test across molecules with varying numbers of atoms as is done in this work. 
Figure  1:  Example  of  choosing  a  value  ùúå(cid:3548)  which 
captures 98% of all errors (ùúÄ) over 1.5 kcal/mol on the 
GDB07to09  benchmark  set  using  the  initial  (before 
using active learning) ANI model ensemble. The value 
which accomplished this is found to be ùúå(cid:3548) = 0.23. This 
value of ùúå(cid:3548) used in query by committee results in the 
selection of 58% of all test data. Initially 26% of all ùúÄ 
are greater than 1.5. 44% of ùúÄ corresponding to œÅ > ùúå(cid:3548) 
are greater than 1.5. Splitting the dataset along œÅ = ùúå(cid:3548) 
results in a total energy RMSE of the ANI ensemble 
prediction vs. reference DFT of 7.4 kcal/mol for all 
values œÅ >   ùúå(cid:3548) and 1.5 kcal/mol for all values œÅ ‚â§   ùúå(cid:3548). 
(cid:3002)(cid:3015)(cid:3010)}(cid:3036)
(cid:3032)(cid:3041)(cid:3046) ‚àí ùê∏(cid:3021),(cid:3036)
Figure 1 provides an example of how the inclusion criterion ùúå(cid:3548) is determined. In this 2-dimensional 
(cid:3019)(cid:3006)(cid:3007))(cid:3627)/(cid:3493)ùëÅ(cid:3036)  where  ùëÅ(cid:3036)  is  the  number  of  atoms  in  the  ith 
density  plot,  ùúÄ(cid:3036) = (cid:3627)ùëÄùê¥ùëã({ùê∏(cid:3021)
molecule. Therefore,  ùúÄ(cid:3036) is the largest per atom prediction error of any model in an ensemble of 
ANI models for test molecule  i. The test data used in this example is the GDB07to09 test set, 
which is described in Section IIC. The ANI model used to determine ùúå(cid:3548) in this example is the ANI 
model which initialized the AL process (Section IIB). The value ùúå(cid:3548) is determined from the choice 
of what value of  ùúÄ is considered too large, and what percentage of epsilon over that should be 
considered as fail cases. Therefore,  ùúå(cid:3548) = 0.23 was empirically selected as it is the value which 
allows selection of 98% of all ùúÄ(cid:3036) > 1.5 kcal/mol.  
The example from Figure 1 determines ùúå(cid:3548) = 0.23 kcal/mol leads to the selection of 58% of all test 
data as molecules that fail the agreement test. As evidence that the choice of  ùúÄ(cid:3036) allows for the 
statistical determination of poorly fit data, it is shown that before selecting any data (i.e. for all ùúå(cid:3036)), 
26% of the complete test set ùúÄ(cid:3036) are greater than 1.5. However, this is 44% when considering all 
ùúÄ(cid:3036) > 1.5  kcal/mol  which  correspond  to  ùúå(cid:3036) > ùúå(cid:3548) .  This  shows  that  the  determined  ùúå(cid:3548) leads  to  a 
selection  of  data  with  a  greater  number  of  ùúÄ(cid:3036) > 1.5  kcal/mol  within  its  population.  As  further 
validation  of  the  approach,  the  application  of  the  concept  is  shown  to  choose  ‚Äúbad‚Äù  data  by 
calculating the RMSE of the potential energy (ùê∏) for the mean prediction of the ensemble of ANI 
models vs. reference DFT calculations. For all ùëñ molecular structures corresponding to ùúå(cid:3036) >   ùúå(cid:3548), the 
ùê∏ RMSE is 7.4 kcal/mol. On the other hand, for all ùëñ molecular structures corresponding to ùúå(cid:3036) ‚â§
ùúå(cid:3548) the ùê∏ RMSE is 1.5 kcal/mol. Therefore, in a statistical way, the method chooses new data which 
is significantly higher in error compared to GDB07to09, which is randomly generated. 
With enough processing time on HPC resources, the rate-limiting step of a QBC data selection 
cycle using ANI potentials is the training of a new ensemble of ANI models. Complete training of 
a single network takes 40 minutes per one million data points on a single NVIDIA Tesla V100 
GPU. To reduce the number of models trained, QBC is used in batches, searching configurational 
and conformational (chemical) space for tens of thousands of new reference data points that fail 
the  agreement  test.  Finally,  labels  (reference  potential  energies, ùê∏(cid:3019)(cid:3006)(cid:3007))  are  computed  for  all 
molecules  in  the  selected  batch.  This  process  may  lead  to  some  redundant  data;  however,  the 
alternative, retraining a new model ensemble after the addition of every new data point, will be 
impractically slow. 
B. Automatic chemical space sampling via active learning 
 
Figure 2. Fully automated AL workflow for data generation. The algorithm contains 3 steps: a) an 
existing dataset reduction, b) a configurational search, and c) a conformational search. 
Figure 2 shows the overall workflow of the iterative AL algorithm. The algorithm is initialized 
from  an  existing  random  sampling  generated  dataset,  which  may  contain  large  amounts  of 
redundant  data.  This  initial  dataset  (ANI-1  in  this  work)  is  then  reduced  through  an  iterative 
approach  with  the  goal  of  minimizing  the  overall  dataset  size  while  not  impacting  predictive 
performance. The reduction algorithm is provided in detail in Figure 2a. Figure 2a is initialized 
with a random subsampled 2% of the original ANI-1 dataset. Then, iteratively, the remaining data 
are tested, and 2% subsets of the fail cases are added to the training set. Here, a fail case is defined 
as |ùê∏(cid:3002)(cid:3015)(cid:3010) ‚àí ùê∏(cid:3005)(cid:3007)(cid:3021)|/‚àöùëÅ   >  0.04 ùëòùëêùëéùëô/ùëöùëúùëô, where N is the number of atoms in the molecule. The 
algorithm  is  terminated  when  less  than  5%  of  the  data  not  yet  added  to  the  training  set  are 
considered as fail cases. The remaining < 5% high error data are added to the final dataset. Hyper-
parameters for the reduction algorithm can be tuned to further reduce redundancies in the data, at 
the  cost  of  more  cycles,  and  therefore,  longer  run  time.  The  final  reduced  dataset  is  used  to 
bootstrap the remaining cycles of the active learning algorithm. If a dataset such as ANI-1 is not 
available, this step can be replaced with the generation of a small amount randomly sampled data 
across many small, four to five C, N, O atoms, molecules. However, this will lead to more active 
learning cycles required before achieving the desired result. 
With the reduced dataset, the configurational search (Figure 2b) is initialized. The configurational 
search is carried out by randomly sampling an external database of small molecules (e.g. GDB-
1151,52,  ChEMBL53‚Äì55,  algorithmically  generated  dipeptides  using  RDKit  [www.rdkit.org], 
automatically  generated  dimers),  embedding  the  molecule  in  3D  space  with  RDKit,  then 
optimizing  initial  structure  with  the  UFF56  force  field.  See  supplemental  information  Section 
S1.2.3 for details on dimer generation. Next, ANI energies are computed using an ensemble of five 
ANI models trained to the current AL dataset (see Section IID for details on ensemble prediction 
and training). Finally, ùúå(cid:3036) = ùúé(cid:3036)/‚àöùëÅ, where ùúé(cid:3036) is the standard deviation of the ensemble‚Äôs energy 
predictions for molecule i and ùëÅ is the number of atoms in the molecule, is computed. The test of 
whether  to  include  the  molecule  corresponding  to  a  given  ùúå(cid:3036)  is  ùúå(cid:3036) > ùúå(cid:3548).  The  selection  of  ùúå(cid:3548)  is 
explained  in  Section  IIA.  All  molecules  that  fail  this  test  are  included  in  the  new  conformer 
sampling set. Any molecules added to the conformer sampling set are geometry optimized with 
the correct reference QM level of theory using tight SCF and optimization convergence criteria. 
With the configurational search complete, a conformational search cycle (Figure 2c) is initialized, 
whereby the conformer sampling set (a set of equilibrium molecules generated in the configuration 
sampling step) is used to generate a set of new non-equilibrium molecules (ùëã(cid:3552)). The conformers in 
ùëã(cid:3552)  are  generated  via  one  of  three  techniques,  which  are  designed  to  sample  various  regions  of 
chemical space. These sampling techniques are listed below.  
ÔÇ∑  Diverse normal mode sampling (DNMS). A version of normal mode sampling (NMS) as 
presented in our previous work36, but with diversity selection used to reduce redundant data 
and a bias towards near equilibrium structures. A detailed description of DNMS is provided 
in supplemental information (SI) section S1.2.1. 
ÔÇ∑  K random trajectory sampling (RTS). We run short (4 ps) molecular dynamics simulations, 
with an ensemble of ANI networks, starting  with random velocities  equal to 300K and 
heated slowly to 1000K over the simulation time. During the dynamics, every step QBC is 
used to check whether the current structure fails the agreement test. Once a structure is 
reached that fails the test, the simulation is terminated, and new QM data is generated for 
inclusion in the training set. This is repeated to generate multiple new samples. A detailed 
description of RTS is provided in SI section S1.2.2. 
ÔÇ∑  Molecular dynamics generated dimer sampling. Dimers are generated by randomly placing 
and orienting molecules from the conformer sampling set into a box with periodic boundary 
conditions. A molecular dynamics simulation for 5ps is then carried out on the box. Every 
50 steps the box is fragmented into only dimer pairs within the desired cutoff radius. Each 
new dimer pair is tested using the QBC approach, failed tests are kept as new data, and QM 
properties are generated for inclusion in the training set. A detailed description of the dimer 
sampling approach used here is provided in SI section S1.2.3. 
After new data is selected, labels are computed and included in the training set, a new ensemble 
of ANI potentials is trained. The conformational search cycles are repeated until the model stops 
improving within the COMP6 benchmarks (see details in Section IIC). Finally, the entire cycle is 
restarted from the configurational sampling step. This process is carried out to produce a total of 
37 cycles including many configurational and conformational searching cycles. Throughout this 
work we will refer to various intermediate active learned ANI models as AL1 through AL6. The 
AL6 potential is the final potential reached in this work and is referred to as the ANI-1x potential, 
which is provided for free in a python package integrated with the atomic simulation environment 
(ASE)  package57  [https://github.com/isayev/ASE_ANI].  The  first  row  in  Table  1  provides 
information about the final dataset from this work, labeled as ANI-1x. Notably, the size of the 
ANI-1x dataset, at 5.5 million structures, is 25% the size of the dataset used in training the original 
ANI-1 potential (22M). 
C. Development of the COMP6 benchmark suite 
Table 1: Description of the final active learning generated training dataset (ANI-1x) and all six COMP6 
benchmark datasets. Mean relative energy range is the average range of relative energies for each set of 
conformers. Energy prediction range is the real prediction range in the benchmark; this is the range which 
the ANI model predicts energies in. [energy units:  kcal/mol] 
Purpose 
Dataset 
Training 
Testing 
ANI-1x 
S66x8 
ANI-MD 
GDB7to9 
GDB10to13 
Tripeptides 
DrugBank 
Molecule 
Source 
ANI-1 + AL 
S66x8 
PDB 
GDB-11 
GDB-13 
RDKit 
DrugBank 
Configurations 
(Conformations) 
63,865 (5,496,771) 
66 (528) 
14 (1,791) 
1,500 (36,000) 
2,996 (47,670) 
248 (1,984) 
837 (13,379) 
Atoms/Molecule 
mean (std. dev.) 
Mean Relative 
Energy Range  
15 (5) 
20 (7) 
75 (72) 
17 (3) 
25 (4) 
53 (7) 
44 (20) 
97.6 
6.00 
35.0 
78.0 
214.0 
102.0 
167.0 
Energy Prediction 
Range  
6,400 
2,800 
31,000 
1,900 
2,300 
4,200 
14,000 
To  validate  that  the active  learning process  generates  an ANI  potential  which  outperforms  the 
original  ANI-1  potential,  and  that  each  cycle‚Äôs  resulting  AL  ANI  potentials  consistently 
outperforms  previous  versions  of  AL  ANI  potentials,  we  develop  the  comprehensive  machine 
learned  potential  (COMP6)  benchmark.  COMP6  is  a  benchmark  suite  composed  five  rigorous 
benchmarks that cover broad regions of organic and bio-chemical space (for molecules containing 
C,  N,  O,  and  H  atoms)  and  a  sixth  built  from  the  existing  S66x849  noncovalent  interaction 
benchmark.  The five new benchmark sets are referred to as GDB7to9, GDB10to13, Tripeptides, 
DrugBank, and ANI-MD. See Table 1 for a detailed description. The benchmarks range from a 
mean  molecule  size  of  17  atoms  to  75  atoms,  with  the  largest  being  312  atoms.  Below  is  a 
description  of  the  methods  used  to  develop  each  benchmark.  Energies  and  forces  for  all  non-
equilibrium molecular conformations presented have been calculated using the œâB97x58 density 
functional with the 6-31G(d) basis set59 as implemented in the Gaussian 0960 electronic structure 
software. Hirshfeld charges and molecular dipoles are also included in the benchmark. An analysis 
of these properties will be done in future work. 
ÔÇ∑  S66x8  Benchmark.  This  dataset  is  built  from  the  original  S66x849  benchmark  for 
comparing accuracy between different methods in describing noncovalent interactions of 
biological molecules. S66x8 is developed from 66 dimeric systems involving hydrogen 
bonding, pi-pi stacking, London interactions, and mixed influence interactions. While the 
keen reader might question the use of this benchmark without dispersion corrections, since 
dispersion  corrections  such  as  the  D361  correction  by  Grimme  et  al.  are  a  posteriori 
additions to the produced energy, then a comparison without the correction is equivalent 
to a comparison with the same dispersion corrections applied to both models. 
ÔÇ∑  ANI Molecular Dynamics (ANI-MD) Benchmark. Forces from the ANI-1x potential are 
applied to run 1ns of vacuum molecular dynamics with a 0.25fs time step at 300K using 
the Langevin thermostat on 14 well-known drug molecules and two small proteins. System 
sizes  range  from  20  to  312  atoms.  A  random  subsample  of  128  frames  from  each  1ns 
trajectory is selected, and reference DFT single point calculations are performed to obtain 
QM energies and forces. 
ÔÇ∑  GDB7to9 Benchmark. The GDB-11 subsets containing 7 to 9 heavy atoms (C, N, and O) 
are subsampled and randomly embedded in 3D space using RDKit [www.rdkit.org]. A total 
of 1500 molecule SMILES [opensmiles.org] strings are selected: 500 per 7, 8, and 9 heavy-
atom set. The resulting structures are optimized with tight convergence criteria, and normal 
modes/force  constants  are  computed  using  the  reference  DFT  model.  Finally,  diverse 
normal mode sampling (DNMS) is carried out to generate non-equilibrium conformations. 
ÔÇ∑  GDB10to13  Benchmark.  Subsamples  of  500  SMILES  strings  each  from  the 10  and  11 
heavy-atom subsets of GDB-1151,52 and 1000 SMILES strings from the 12 and 13 heavy-
atom  subsets  of  the  GDB-1362  database  are  randomly  selected.  DNMS  is  utilized  to 
generate random non-equilibrium conformations. 
ÔÇ∑  Tripeptide Benchmark. 248 random tripeptides containing H, C, N, and O are generated 
using  FASTA  strings  and  randomly  embedded  in  3D  space  using  RDKit.  As  with 
GDB7to9, the molecules are optimized, and normal modes are computed. DNMS is utilized 
to generate random non-equilibrium conformations. 
ÔÇ∑  DrugBank  Benchmark.  This  benchmark  is  developed  through  a  subsampling  of  the 
DrugBank63 database of real drug molecules. 837 SMILES strings containing C, N, and O 
are randomly selected. Like the GDB7to9 benchmark, the molecules are embedded in 3D 
space,  structurally  optimized,  and  normal  modes  are  computed.  DNMS  is  utilized  to 
generate random non-equilibrium conformations. 
D. Error metrics for validation on the COMP6 benchmark suite 
This work uses three error metrics for comparing different versions of ANI potentials: potential 
energy (ùê∏), conformer energy difference (‚àÜùê∏), and atomic force component errors (ùêπ).  
ÔÇ∑  Potential energy (ùê∏) error is a comparison of  ùê∏(cid:3036)
(cid:3014)(cid:2869), potential energies produced by model 
M1 for molecule i, to ùê∏(cid:3036)
(cid:3014)(cid:2870), the potential energies produced by model M2 for molecule i. 
ÔÇ∑  The  conformer  energy  difference  (‚àÜùê∏)  error is  calculated  per  set  of  conformers.  In  the 
benchmark dataset K sets of conformers are supplied, one per molecular configuration. For 
a given set of conformers k, the conformer energy difference between conformers ùëñ and ùëó 
(cid:3014),(cid:3038). Finally, error is 
for a given model M is obtained by computing ‚àÜùê∏(cid:3036)(cid:3037)
(cid:3014)(cid:2870),(cid:3038) for all k, ùëñ, and ùëó > ùëñ + 1 for models M1 and M2.  
calculated between ‚àÜùê∏(cid:3036)(cid:3037)
ÔÇ∑  The atomic force (ùêπ) error metric is a comparison between the individual components (x, 
(cid:3014)(cid:2869),(cid:3038) and ‚àÜùê∏(cid:3036)(cid:3037)
(cid:3014),(cid:3038)   =   ùê∏(cid:3036)
(cid:3014),(cid:3038)   ‚àí   ùê∏(cid:3037)
y, z) of each atom‚Äôs force vector for all conformations included in the given benchmark. 
Comparisons  are  given  in  mean  absolute  error  (MAE),  and  root  mean  squared  error  (RMSE) 
throughout this article. The comparison of MAE along with RMSE can give information about 
outliers in a model‚Äôs predictions. For example, two models can have the same MAE for a prediction 
on a given benchmark while the RMSE can be much higher for one than the another. For this 
reason, it is good practice to provide both MAE and RMSE when comparing two methods on some 
benchmark. 
E. Property prediction with an ensemble of ANI models 
For energy and force prediction we use the mean prediction of an ensemble of ANI potentials. The 
concept  of  using  an  ensemble  mean  for  ML  model  prediction  is  common  practice  in  the  ML 
community. Recently, it has been adopted in the area of ML molecular property prediction.23,37,64 
All potentials used to generate results in this work utilize the mean prediction for an ensemble of 
ùêø = 5 ANI potentials trained to a 5-fold cross validation split of the training dataset. The potential 
energy (ùê∏) is represented by, 
ùê∏ =
(cid:3013)
(cid:3533) ùê∏(cid:3036)
(cid:3036)(cid:2880)(cid:2869)
where ùê∏(cid:3036) is the potential energy prediction from each of an ensemble‚Äôs ùêø ANI models. Since the 
models are independent, atomic forces for the ensemble can be derived as the component wise 
mean of the forces from the ùêø individual ANI models. The use of an ensemble as described above 
decreases ANI vs. DFT ùê∏ RMSE by 0.67 kcal/mol, ‚àÜùê∏ RMSE by 0.68 kcal/mol, and ùêπ RMSE 
by 2.1‚Äàkcal/mol √ó ‚Äà√Ö(cid:2879)(cid:2869) over the entire COMP6 benchmark. 
 III. RESULTS AND DISCUSSIONS 
The supplemental information (SI) provided with this work contains various tables detailing the 
results obtained on the COMP6 benchmark by the ANI potentials discussed in this work. SI tables 
S1 through S7 provide an analysis of the ‚àÜùê∏, ùê∏, and ùêπ errors obtained for six subsequent active 
learned ANI potentials, AL1 through AL6, and the original ANI-1 potential. Note that the publicly 
released ANI-1x potential is identical to the AL6 ANI potential. SI Tables S8 through S10 supply 
an  analysis  of  the  individual  ANI-MD  trajectory  results  for  the  ANI-1x  potential.  Table  S9 
provides per atom energy errors for the ANI-1x potential vs. DFT and shows that the mean energy 
prediction RMSE per atom for all trajectories is 0.05 kcal/mol per atom. This level of accuracy is 
on par with single molecule or bulk metal ML potentials as described in recent work by J. Behler.26 
SI Table S11 provides details on the ANI models introduced in this work. Finally, SI Tables S12 
Figure 3. Force correlation plots comparing ANI-1x, DFTB (3ob-3-1 parameter set for bio-molecules), and PM6 
to DFT reference calculations are provided from left to right, respectively, for the complete ANI-MD benchmark. 
Molecules  in  the  ANI-MD  benchmark  are  composed  of  a  mean  of  75  atoms  with  the  largest  being  Trp-cage 
(1L2Y), a 20-residue (312-atom) protein. DFTB and PM6 are provided as a baseline of comparison. Mean absolute 
errors (MAE) and root mean squared errors (RMSE) are provided in the bottom right of each figure. The color bar 
scale is the same for all figures allowing a proper density comparison.  
through S17 give errors on conformers within select energy ranges for the ANI-1x potential. These 
tables  show  much  lower  errors  for  conformations  which  are  thermally  accessible  to  room 
temperature  molecular  dynamics  simulations.  As  shown  in  Table  S17,  thermally  accessible 
conformations (within 50kcal/mol) have a ùê∏ MAE/RMSE of 0.064/0.105 kcal/mol per atom and 
‚àÜùê∏ MAE/RMSE of 0.049/0.070 kcal/mol per atom over the complete COMP6 benchmark.   
Figure 3 provides evidence of the ANI-1x force prediction capabilities. Also, most tables in the 
supplemental information further establish the accuracy of ANI potential force prediction on the 
COMP6  benchmark  suite.  By  construction,  ANI  potentials  provide  analytic  and  energy-
conservative forces, a requirement for molecular dynamics simulations. It is noteworthy that force 
training,  which  can  be  computationally  expensive,  is  not  required  to  achieve  these  force 
prediction results. The forces compared in the DFT correlation density plots in Figure 3 are from 
all trajectories combined in the COMP6 ANI-MD benchmark. We compare the same figures for 
ANI-1x (left), DFTB (center), and PM6 (right). DFTB and PM6 are included as a baseline for the 
comparison.  This  is  a  rigorous  test  case  for  any  ML  potential‚Äôs  force  prediction  because  the 
molecules supplied in the dataset range from 20 to 312 atoms, with an average size of 75 atoms. 
A  breakdown  of  the  errors  for  each  trajectory  in  the  ANI-MD  benchmark  is  supplied  in  the 
supplemental information, Tables S8 through S10.  
The closest comparison in literature can be found in recent work on a system specific ML potential 
for an alanine tripeptide where a force RMSE of 3.4  kcal/mol √ó √Ö(cid:2879)(cid:2869) was achieved with test data 
from  a  350K  MD  trajectory.37  The  force 
error  from  this  work  was  obtained  by 
training  directly  to  energies  and  analytic 
forces from fragments of the molecule being 
tested. In the case of the ANI-1x potential, 
which was used to predict the forces for the 
creation  of  the  ANI-MD  benchmark,  a 
MAE/RMSE  of  2.7/4.2  kcal/mol √ó √Ö(cid:2879)(cid:2869)  is 
obtained  vs.  a  posteriori  DFT  calculations 
on 128 random frames from each of the 14 
molecule‚Äôs 
dynamics 
trajectories.  More 
ùêπ 
MAE/RMSE for the neutralized 20-residue 
Trp-cage (1L2Y) and 10-residue Chignolin 
(1UAO)  proteins  are  3.1/4.6  kcal/mol √ó
√Ö(cid:2879)(cid:2869) 
kcal/mol √ó √Ö(cid:2879)(cid:2869), 
respectively.  ANI-1x  also  exhibits  a  force 
MAE/RMSE  of  2.3/3.3  kcal/mol √ó √Ö(cid:2879)(cid:2869) 
within the energy range of 50 kcal/mol on 
the  tripeptide  benchmark  (non-equilibrium 
conformations 
randomly 
generated  tripeptides)  from  COMP6  (see 
supplemental 
information  Table  S14), 
Figure  4.  Comparison  of  potential  energy  (E)  RMSE 
obtained on the entire COMP6 benchmark vs. training set 
size (total molecular conformation included in the training 
set).  The  x-axis  represents  the  progression  of  the  active 
learning  process.  Plot  points  are  obtained  by  ANI 
potentials (blue) trained to various versions of the active 
learned dataset and an ANI potential (red) trained on the 
original ANI-1 dataset. 
1ns  molecular 
from 
248 
impressive, 
and 
3.3/4.7 
which is roughly the accessible energy range of 350K molecular dynamics simulations. Finally, 
considering  the  ANI-1x  potential  was  utilized  to  generate  1  ns  of  300K  molecular  dynamics 
simulations,  from  which  the  ANI-MD  benchmark  geometries  were  sampled,  speaks  to  the 
applicability of the forces in molecular dynamics for general molecular systems. All the previously 
mentioned  results  from  the  ANI-1x  potential  were  obtained  without  the  need  of  direct  force 
training.  
Figure 4 provides a plot of ùê∏ RMSE achieved on COMP6 vs. dataset size for various active learned 
datasets and the original ANI-1 dataset. With only 2 million data points, the active learned ANI 
potentials already outperform the original ANI-1 potential across the entire COMP6 benchmark. 
Once the active learned ANI potential reaches 5.5 million data points it five times outperforms 
ANI-1 and is approaching chemical accuracy from the reference DFT calculations.  In the new 
COMP6 benchmark, diversity selection in the normal mode sampling helps ensure a more uniform 
sampling of energy states within the energy range being fit to and tested within. Therefore, general 
errors on COMP6 vs. the ANI-1 potential‚Äôs original results are expected to be much higher on this 
complex benchmark than the results published on the less rigorous test sets from the original ANI-
1 work. Table 1 provides the average energy ranges for each benchmark in COMP6 and the final 
training set (ANI-1x), as well as the energy prediction (atomization energy) range.  
Most  benchmarks  in  COMP6  (all  but  the  ANI-MD  benchmark)  were  used  during  the  active 
learning process to validate the improvement in accuracy and universality of new active learned 
ANI  models.  Figure  5  provides  the  learning  curves  for  six  intermediate  active  learned  ANI 
potentials  on  each  benchmark  in  COMP6.  Supplemental  information  Table  S11  provides 
information of the chemical space sampled in each of these datasets. The horizontal dashed lines 
Figure 5. Individual COMP6 benchmark learning curves for successive versions of the active learned potentials. 
RMSE  is  provided  for  three  properties:  potential  energy  (ùê∏),  conformer  energy  differences  (‚àÜùê∏),  and  force 
components (ùêπ). The error bars on the solid lines represent one standard deviation of each of the five ANI models 
in the ensemble used to make the mean prediction. The horizontal lines represent the mean prediction of ANI-1. 
in Figure 5 represent the original ANI-1 ensemble predictions on each of the benchmarks for the 
property corresponding to its color.  AL1 is the ANI potential used to initialize the active learning 
process. It was trained to a reduced (Figure 2a) version of the one through six heavy atom subsets 
of  the  ANI-1  dataset.  AL2  through  AL6  are  successive  versions  of  the  active  learned  ANI 
potentials. More details for each active learning cycle shown in Figure 5 is provided in SI Table 
S11. During the active learning process, small molecules (one to six C, N, and O atoms) were 
initially sampled, with the size of the molecules sampled gradually increased as the active learning 
process continued. AL3 is where the AL models begin to statistically match or outperform the 
original ANI-1 model in most metrics. It is notable that AL3 accomplished this feat while only 
having sampled 1.8 million conformations from molecules with up to 7-heavy atoms from GDB-
11. This shows that the active learning techniques employed in this work sample chemical space 
far better than random sampling techniques. Especially considering the ANI-1 dataset includes 22 
million conformations from larger, up to 8-heavy atom, molecules.  
Eventually, between the AL4 and AL5 steps, amino acids, generated dipeptides, generated small 
molecule dimers and small ChEMBL molecules were added to the sampling set. This is apparent 
from the large drop in error between AL4 and AL5 for the DrugBank, Tripeptides, and S66x8 
benchmarks. Active learning sampling was also driven into the GDB-11‚Äôs 9-heavy atom subset for 
sampling during the production of AL6. Supplemental information Tables S2 through S7 provide 
the full tables used to make Figure 5 along with Table S1 which describes all benchmarks at once. 
The latest ANI potential, ANI-1x (shown as AL6), achieves remarkable property prediction on the 
complete benchmark with errors (MAE/RMSE) of 1.9/3.4 kcal/mol (ùê∏), 1.8/3.0 kcal/mol (‚àÜùê∏), 
and 3.1/5.3 kcal/mol √ó √Ö(cid:2879)(cid:2869) (F) within the full energy range of the benchmark. 
In general, as each ANI potential‚Äôs fitness improves in Figure 5, the standard deviation (shown as 
vertical error bars) of each property prediction for a given ensemble decreases as well. This is a 
sign that each model in the ensemble is obtaining enough chemical interaction information through 
active learning that the models begin agreeing on their predictions for these larger systems. By the 
final iteration of the active learning cycles, an active learned dataset of 5.5M data points is used in 
training  the  ANI-1x  potential.  The  ANI-1x  potential  outperforms  the  ANI-1  potential  on  all 
properties across all benchmarks. Further, the ANI-1x dataset is 25% the size of the original ANI-
1 dataset, which contains a total of 22M data points.   
In the process of submitting this paper we learned about recent work from Herr et al.65 It was 
cautioned  that  using  a  specific  sampling  technique  (i.e.  MD,  normal  mode,  or  meta-dynamics 
sampling) to measure the accuracy of an ML potential says nothing about how well that model 
performs outside of that specific sampling technique: ‚ÄúNo measure of a [ML potential] to a single 
sampling  technique  contains  quantitative  information  about  general  performance  outside  that 
sampling technique.‚Äù65 While we agree this statement is true for system specific potentials and test 
sets where, for example, NMS will only sample near a very specific energy minima, it does not 
hold  for  universal  ML  potentials  and  test  sets  that  span  chemically  relevant  regions  of 
conformational and configurational (chemical) space. With the following three points we argue 
this statement is false with regards to the NMS sampling in the COMP6 benchmark. First, the 
configurational sampling conducted for COMP6 is a random sampling of out-of-sample molecules 
with a random 3D embedding through RDKit. Second, the NMS used to generate states away from 
the energy minima overlaps with states produced by MD sampling techniques. Third, restraints to 
specific  energy  ranges  allow  controlled  tests  within  thermally  accessible  regions  of  chemical 
space, the same space sampled by MD. Therefore, if a large set of out-of-sample molecules is used 
and the entire thermally accessible region of interest is considered, quantitative information about 
how well the universal ML potential performs in MD simulations is obtained regardless of the 
sampling technique used. As empirical evidence of this, the ANI-1x potential tested on the ANI-
MD  benchmark  (mean  energy  range  of  35 kcal/mol)  has  a  F  MAE/RMSE  of  2.49/3.77 
kcal/mol √ó √Ö(cid:2879)(cid:2869) (SI Table S10). Compare this with the complete COMP6 benchmark (95% NMS 
sampled  test  data)  restricted  to  an  energy  range  of  50 kcal/mol;  it  exhibits  a  F  MAE/RMSE 
kcal/mol √ó √Ö(cid:2879)(cid:2869) of 2.48/4.11 (SI Table S12). The standard deviation of each model‚Äôs prediction 
on MD vs. NMS sampled data places them within a reasonable statistical fluctuation. From this, a 
conclusion can be drawn that the NMS test data provides quantitative information about how well 
the model will perform on samples from random MD simulations. 
IV. CONCLUSIONS  
In  pursuit  of  automated  dataset  generation  for  the  development  of  universal  machine  learned 
potentials,  we  introduce  automatic  active  learning  techniques  for  sampling  sparsely  explored 
regions of chemical space. The algorithm begins with the reduction of an existing dataset to remove 
redundant data without loss of accuracy. New conformations of molecules are generated through 
normal mode sampling, molecular dynamics sampling, and random dimer sampling. Periodically 
the  algorithm  samples  new  molecular  configurations  from  a  variety  of  sources  to  diversify  its 
exploration of chemical space. The result is a new potential (ANI-1x) developed though successive 
generations of the active learning process. The ANI-1x potential is packaged in a user-friendly 
Python library, which is publicly available on GitHub [https://github.com/isayev/ASE_ANI]. We 
also introduce the COMP6 benchmark for monitoring the progress of active learning cycles and 
for comparison to future universal potentials. The ANI-1x potential achieves errors (MAE/RMSE) 
of 1.6/3.0 kcal/mol (ùê∏), 1.4/2.3 kcal/mol (‚àÜùê∏), and 2.7/4.5 kcal/mol √ó √Ö(cid:2879)(cid:2869) (F) when testing on 
points within 100 kcal/mol of the energy minima for the complete COMP6 benchmark. 
available 
for 
is  made 
publicly 
comparing 
The COMP6 benchmark suite consists of six diverse benchmark test sets. The COMP6 benchmark 
suite 
potentials 
[https://github.com/isayev/ANI1_dataset]. As provided, properties are calculated using the œâB97x 
density functional with the 6-31G(d) basis set, however, it could be recomputed using the desired 
quantum level of theory. For complete transparency, we provide the exact error metrics used to 
measure accuracy on the COMP6 benchmark suite. It is our hope that the COMP6 benchmark will 
provide  the  universal  ML  potential  development  community  with  a  rigorous  benchmark  for 
comparison  of  ML  potential  methods  on  organic  molecules  in  the  extrapolative  regime.  The 
COMP6 benchmark suite constitutes a first benchmark of its kind for the comparison of universal 
ML potentials in this rapidly changing and ever-growing field.  
future  ML 
The ANI-1x potential was trained to less than 100 conformations per molecular configuration in 
its training set, compared to 400 for the ANI-1 dataset. The accuracy of the ANI-1x potential is on 
par  with  the  best  single  molecule  or  material  ML  potentials,  while  most  single  molecule 
parametrized ML potentials require many hundreds to thousands of conformations to parametrize 
a single system. This further validates the configurational and conformational big data sampling 
philosophy introduced in the original ANI-1 work. Since the mean molecule size in the ANI-1x 
active learning training set is only 15 total atoms (8 heavy atoms), the generation of more accurate 
post-Hartree-Fock datasets plausible. 
The high-level of universal accuracy achieved by the ANI-1x potential can be attributed to the 
capacity of neural networks to learn low level interactions from properly developed descriptors. 
We hypothesize the use of spatially localized descriptors (i.e., the atomic environment vector34 
with modified angular symmetry function) within the cutoff to contribute greatly to this ability. 
This contrasts with descriptor sets that represent the entire chemical environment at once, and thus 
interactions must be inferred through the entire set of non-local descriptors by the ML model.  
Given the prospects of high-throughput experiments, robotic synthesis, and intelligent software, 
we  are  currently  witnessing  a  transformation  of  science  into  a  more  data-driven  automated 
discovery.  The  envisioned  chemical  AI  imitates  human  decision  making  by  transferring 
responsibility to an objective machine learning system. If successful overall, the approach will 
revolutionize the way computational methods are developed. As one possible building block to 
construct such AI, we introduced a fully automated workflow to select and calculate QM training 
data  for  accurate,  transferable,  and  extensible  ML  potentials.  These  techniques  can  aid  in  the 
generation of universal potentials for a wide variety of current and future ML models.  
SUPPLEMENTARY INFORMATION  
ACKNOWLEDGEMENTS  
J.S.S thanks the University of Florida for the graduate student fellowship and the  Los Alamos 
National Laboratory Center for Non-linear Studies for resources and hospitality. This work was 
performed,  in  part,  at  the  Center  for  Integrated  Nanotechnologies,  an  Office  of  Science  User 
Facility  operated  for  the  U.S.  Department  of  Energy  (DOE)  Office  of  Science.  Los  Alamos 
National Laboratory, an affirmative action equal opportunity employer, is operated by Los Alamos 
National Security, LLC, for the National Nuclear Security Administration of the U.S. Department 
of  Energy  under  contract  DE-AC52-06NA25396.  O.I.  acknowledges  support  from  DOD-ONR 
(N00014-16-1-2311)  and  Eshelman  Institute  for  Innovation  award.  The  authors  acknowledge 
Extreme Science and Engineering Discovery Environment (XSEDE) award DMR110088, which 
is supported by National Science Foundation grant number ACI-1053575. This research in part 
was  done  using  resources  provided  by  the  Open  Science  Grid66,67  which  is  supported  by  the 
National  Science  Foundation  award  1148698,  and  the  U.S.  Department  of  Energy's  Office  of 
Science. We gratefully acknowledge the support of the U.S. Department of Energy through the 
LANL/LDRD Program for this work. The authors thank Roman Zubatyuk and Kipton Barros for 
invaluable discussions on the topics presented in this work. 
APPENDIX 
1 J.A. Maier, C. Martinez, K. Kasavajhala, L. Wickstrom, K.E. Hauser, and C. Simmerling, J. 
Chem. Theory Comput. 11, 3696 (2015). 
2 K. Vanommeslaeghe, E. Hatcher, C. Acharya, S. Kundu, S. Zhong, J. Shim, E. Darian, O. 
Guvench, P. Lopes, I. Vorobyov, and A.D. Mackerell, J. Comput. Chem. 31, 671 (2010). 
3 T.A. Halgren, J. Comput. Chem. 17, 490 (1996). 
4 K.S. Thanthiriwatte, E.G. Hohenstein, L.A. Burns, and C.D. Sherrill, J. Chem. Theory Comput. 
7, 88 (2011). 
5 H.J. Monkhorst, Int. J. Quantum Chem. 12, 421 (1977). 
6 G.D. Purvis and R.J. Bartlett, J. Chem. Phys. 76, 1910 (1982). 
7 D. Cremer, Wiley Interdiscip. Rev. Comput. Mol. Sci. 1, 509 (2011). 
8 J. Huang and A.D. Mackerell, J. Comput. Chem. 34, 2135 (2013). 
9 H. Sun, J. Phys. Chem. B 102, 7338 (1998). 
10 K.N. Kirschner, A.B. Yongye, S.M. Tschampel, J. Gonz√°lez-Outeiri√±o, C.R. Daniels, B.L. 
Foley, and R.J. Woods, J. Comput. Chem. 29, 622 (2008). 
11 J.A. Maier, C. Martinez, K. Kasavajhala, L. Wickstrom, K.E. Hauser, and C. Simmerling, J. 
Chem. Theory Comput. 11, 3696 (2015). 
12 T. Moot, O. Isayev, R.W. Call, S.M. McCullough, M. Zemaitis, R. Lopez, J.F. Cahoon, and A. 
Tropsha, Mater. Discov. 6, 9 (2016). 
13 M. Ragoza, J. Hochuli, E. Idrobo, J. Sunseri, and D.R. Koes, J. Chem. Inf. Model. 57, 942 
(2017). 
14 B. Liu, B. Ramsundar, P. Kawthekar, J. Shi, J. Gomes, Q. Luu Nguyen, S. Ho, J. Sloane, P. 
Wender, and V. Pande, ACS Cent. Sci. 3, 1103 (2017). 
15 J.N. Wei, D. Duvenaud, and A. Aspuru-Guzik, ACS Cent. Sci. 2, 725 (2016). 
16 R. Ramakrishnan, P.O. Dral, M. Rupp, and O.A. Von Lilienfeld, J. Chem. Theory Comput. 11, 
2087 (2015). 
17 A. Lavecchia, Drug Discov. Today 20, 318 (2015). 
18 O. Isayev, C. Oses, C. Toher, E. Gossett, S. Curtarolo, and A. Tropsha, Nat. Commun. 8, 
15679 (2017). 
19 E. Kim, K. Huang, A. Saunders, A. McCallum, G. Ceder, and E. Olivetti, Chem. Mater. 29, 
9436 (2017). 
20 B. Kolb, B. Zhao, J. Li, B. Jiang, and H. Guo, J. Chem. Phys. 144, 224103 (2016). 
21 M. Hellstr√∂m and J. Behler, Phys. Chem. Chem. Phys. 19, 82 (2017). 
22 T.H. Ho, N.-N. Pham-Tran, Y. Kawazoe, and H.M. Le, J. Phys. Chem. A 120, 346 (2016). 
23 N. Lubbers, J.S. Smith, and K. Barros, Preprint at https://arxiv.org/abs/1710.00017 (2017). 
24 K.T. Sch√ºtt, F. Arbabzadah, S. Chmiela, K.R. M√ºller, and A. Tkatchenko, Nat. Commun. 8, 
13890 (2017). 
25 K. Yao, J.E. Herr, S.N. Brown, and J. Parkhill, J. Phys. Chem. Lett. 8, 2689 (2017). 
26 J. Behler, Angew. Chemie Int. Ed. 56, 12828 (2017). 
27 V. Botu, R. Batra, J. Chapman, and R. Ramprasad, J. Phys. Chem. C 121, 511 (2017). 
28 S. Kondati Natarajan, T. Morawietz, and J. Behler, Phys. Chem. Chem. Phys. 17, 8356 (2015). 
29 J. Behler, R. Marto≈à√°k, D. Donadio, and M. Parrinello, in Phys. Status Solidi Basic Res. 
(WILEY‚ÄêVCH Verlag, 2008), pp. 2618‚Äì2629. 
30 K. Yao, J.E. Herr, D.W. Toth, R. Mcintyre, and J. Parkhill, Chem. Sci. (2018). 
31 K. Sch√ºtt, P.-J. Kindermans, H.E. Sauceda Felix, S. Chmiela, A. Tkatchenko, and K.-R. 
M√ºller, in Adv. Neural Inf. Process. Syst. 30, edited by I. Guyon, U. V Luxburg, S. Bengio, H. 
Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Curran Associates, Inc., 2017), pp. 992‚Äì
1002. 
32 R. Ramakrishnan, P.O. Dral, M. Rupp, and O.A. von Lilienfeld, Sci. Data 1, 140022 (2014). 
33 M. Rupp, A. Tkatchenko, K.-R. Muller, and O.A. von Lilienfeld, Phys. Rev. Lett. 108, 58301 
(2012). 
34 J.S. Smith, O. Isayev, and A.E. Roitberg, Chem. Sci. 27, 479 (2017). 
35 J. Behler and M. Parrinello, Phys. Rev. Lett. 98, 146401 (2007). 
36 J.S. Smith, O. Isayev, and A.E. Roitberg, Sci. Data 4, 170193 (2017). 
37 M. Gastegger, J. Behler, and P. Marquetand, Chem. Sci. 8, 6924 (2017). 
38 B. Huang and O. Anatole Von Lilienfeld, Preprint at https://arxiv.org/abs/1707.04146 (2017). 
39 K. Yao, J.E. Herr, D.W. Toth, R. Mcintyre, and J. Parkhill, Preprint at 
http://arxiv.org/abs/1711.06385 (2017). 
40 P. Raccuglia, K.C. Elbert, P.D.F. Adler, C. Falk, M.B. Wenny, A. Mollo, M. Zeller, S.A. 
Friedler, J. Schrier, and A.J. Norquist, Nature 533, 73 (2016). 
41 P.J. Kitson, G. Marie, J.-P. Francoia, S.S. Zalesskiy, R.C. Sigerson, J.S. Mathieson, and L. 
Cronin, Science (80-. ). 359, 314 (2018). 
42 T. Chapman, Nature 421, 661 (2003). 
43 R.D. King, J. Rowland, S.G. Oliver, M. Young, W. Aubrey, E. Byrne, M. Liakata, M. 
Markham, P. Pir, L.N. Soldatova, A. Sparkes, K.E. Whelan, and A. Clare, Science (80-. ). 324, 
85 (2009). 
44 E. V. Podryabinkin and A. V. Shapeev, Comput. Mater. Sci. 140, 171 (2017). 
45 N.J. Browning, R. Ramakrishnan, O.A. von Lilienfeld, and U. Roethlisberger, J. Phys. Chem. 
Lett. 8, 1351 (2017). 
46 P.O. Dral, A. Owens, S.N. Yurchenko, and W. Thiel, J. Chem. Phys. 146, 244108 (2017). 
47 A.A. Peterson, R. Christensen, and A. Khorshidi, Phys. Chem. Chem. Phys. 115, 1074 (2017). 
48 H.S. Seung, M. Opper, and H. Sompolinsky, in Proc. Fifth Annu. Work. Comput. Learn. 
Theory - COLT ‚Äô92 (ACM Press, New York, New York, USA, 1992), pp. 287‚Äì294. 
49 B. Brauer, M.K. Kesharwani, S. Kozuch, and J.M.L. Martin, Phys. Chem. Chem. Phys. 18, 
20905 (2016). 
50 I. Kruglov, O. Sergeev, A. Yanilkin, and A.R. Oganov, Sci. Rep. 7, 8512 (2017). 
51 T. Fink, H. Bruggesser, and J.L. Reymond, Angew. Chemie - Int. Ed. 44, 1504 (2005). 
52 T. Fink and J.L. Raymond, J. Chem. Inf. Model. 47, 342 (2007). 
53 S. Jupp, J. Malone, J. Bolleman, M. Brandizi, M. Davies, L. Garcia, A. Gaulton, S. Gehant, C. 
Laibe, N. Redaschi, S.M. Wimalaratne, M. Martin, N. Le Nov??re, H. Parkinson, E. Birney, and 
A.M. Jenkinson, Bioinformatics 30, 1338 (2014). 
54 A.P. Bento, A. Gaulton, A. Hersey, L.J. Bellis, J. Chambers, M. Davies, F.A. Kr√ºger, Y. 
Light, L. Mak, S. McGlinchey, M. Nowotka, G. Papadatos, R. Santos, and J.P. Overington, 
Nucleic Acids Res. 42, D1083 (2014). 
55 M. Davies, M. Nowotka, G. Papadatos, F. Atkinson, G. van Westen, N. Dedman, R. Ochoa, 
and J. Overington, Challenges 5, 334 (2014). 
56 A.K. Rappe, C.J. Casewit, W.A. Goddard III, K.S. Colwell, and W.M. Skiff, J. Am. 114, 
10024 (1992). 
57 A. Hjorth Larsen, J. J√òrgen Mortensen, J. Blomqvist, I.E. Castelli, R. Christensen, M. Du≈Çak, 
J. Friis, M.N. Groves, B. Hammer, C. Hargus, E.D. Hermes, P.C. Jennings, P. Bjerre Jensen, J. 
Kermode, J.R. Kitchin, E. Leonhard Kolsbjerg, J. Kubal, K. Kaasbjerg, S. Lysgaard, J. 
Bergmann Maronsson, T. Maxson, T. Olsen, L. Pastewka, A. Peterson, C. Rostgaard, J. Schi√òtz, 
O. Sch√ºtt, M. Strange, K.S. Thygesen, T. Vegge, L. Vilhelmsen, M. Walter, Z. Zeng, and K.W. 
Jacobsen, J. Phys. Condens. Matter 29, 273002 (2017). 
58 J. Da Chai and M. Head-Gordon, J. Chem. Phys. 128, 84106 (2008). 
59 R. Ditchfield, W.J. Hehre, and J.A. Pople, J. Chem. Phys. 54, 724 (1971). 
60 G. M. J. Frisch, W. Trucks, H.B. Schlegel, G.E. Scuseria, M.A. Robb, J.R. Cheeseman, G. 
Scalmani, V. Barone, B. Mennucci, G.A. Petersson, H. Nakatsuji, M. Caricato, X. Li, H.P. 
Hratchian, A.F. Izmaylov, J. Bloino, G. Zheng, and J.L. Sonnenberg, Gaussian, Inc. Wallingford, 
CT (2009). 
61 S. Grimme, J. Antony, S. Ehrlich, and H. Krieg, J. Chem. Phys. 132, 154104 (2010). 
62 L.C. Blum and J.-L. Reymond, J. Am. Chem. Soc. 131, 8732 (2009). 
63 V. Law, C. Knox, Y. Djoumbou, T. Jewison, A.C. Guo, Y. Liu, A. Maciejewski, D. Arndt, M. 
Wilson, V. Neveu, A. Tang, G. Gabriel, C. Ly, S. Adamjee, Z.T. Dame, B. Han, Y. Zhou, and 
D.S. Wishart, Nucleic Acids Res. 42, D1091 (2014). 
64 J. Gilmer, S.S. Schoenholz, P.F. Riley, O. Vinyals, and G.E. Dahl, Preprint at 
https://arxiv.org/abs/1704.01212 (2017). 
65 J.E. Herr, K. Yao, R. McIntyre, D. Toth, and J. Parkhill, Preprint at 
http://arxiv.org/abs/1712.07240 (2017). 
66 R. Pordes, D. Petravick, B. Kramer, D. Olson, M. Livny, A. Roy, P. Avery, K. Blackburn, T. 
Wenaus, F. W√ºrthwein, I. Foster, R. Gardner, M. Wilde, A. Blatecky, J. McGee, and R. Quick, 
in J. Phys. Conf. Ser. (IOP Publishing, 2007), p. 12057. 
67 I. Sfiligoi, D.C. Bradley, B. Holzman, P. Mhashilkar, S. Padhi, and F. W√ºrthwein, in 2009 
WRI World Congr. Comput. Sci. Inf. Eng. CSIE 2009 (IEEE, 2009), pp. 428‚Äì432. 
Supplementary information for: ‚ÄúLess is more: 
sampling chemical space with active learning‚Äù 
Justin S. Smith1, Ben Nebgen3, Nicholas Lubbers3, Olexandr Isayev2,*, Adrian E. Roitberg1,* 
1Department of Chemistry, University of Florida, Gainesville, FL 32611, USA 
2UNC Eshelman School of Pharmacy, University of North Carolina at Chapel Hill, Chapel Hill, 
NC 27599, USA 
3Los Alamos National Laboratory, Los Alamos, NM 87545, USA 
* Corresponding authors; email: OI (olexandr@olexandrisayev.com) and AER (roitberg@ufl.edu) 
S1 Methods 
S1.1 ANI Ensemble Preparation 
Single network architectures vary by the size of the data set used to train the models during the 
active learning  process.  Table  S11  describes  all  models  presented  in  this  work.  Network  sizes 
(depth and number of parameters) were determined through hyper parameter searches conducted 
at  every  configurational  sampling  step.  Parameters  for  the  atomic  environment  vector1  (a 
numerical vector used to describe an atoms local chemical environment) used during the active 
learning  process  were  constant  and  are  provided  with  the  released  ANI-1x  model.  An  initial 
learning rate of 0.001 is used. Early stopping is utilized in the training of each network, whereby 
if a model fails to improve its validation set predictions within 75 epochs then training is stopped. 
Learning rate annealing is utilized such that once a model stops early, training is restarted with a 
learning rate 0.5 times that of the previous learning rate. Termination of training is achieved when 
the learning rate is less than 1.0 √ó 10(cid:2879)(cid:2873). The adam2 update method is used to update the weights 
during training.  
Ensembles of ANI potentials are prepared using a 5-fold cross validation split of the data set and 
all previously mentioned hyper parameters. Training the ensemble to a 5-fold cross validation split 
ensures that the ensemble was trained to the entire data set for maximum performance. Rather than 
testing models on a 10% hold out from the training data set, we use benchmarks from the COMP6 
benchmark suite to determine the fitness of an ensembles prediction. We do this because we are 
more  interested  in  getting  potentials  which  are  not  just  accurate  but  also  transferable  and 
extensible. The COMP6 benchmarks provide more rigorous test case than could be achieved by 
testing on a 10% hold out of the training data set since molecules in the benchmarks are on average 
much larger than those included in the training set. This allows testing of extrapolation to larger 
structures,  which  is  of  great  importance  to  any  universal  ML  potential,  rather  than  testing 
interpolation  to  already  seen  molecules.  However,  mean  10%  hold  out  test  set  performance  is 
supplied in Table S11 for the AL models published in this work. 
S1.2 Sampling methods 
S1.2.1 Diverse Normal Mode Sampling (DNMS).  
We modify the normal mode sampling (NMS) technique introduced by Smith el al.1 to avoid data 
set clustering around equilibrium conformations. This technique identically follows NMS, in that 
a molecule is optimized at the desired QM level of theory, œâb97x with the 6-31g(d) basis set in 
this work, then frequency calculations are performed to obtain normal mode coordinates and their 
corresponding harmonic force constants. As with NMS, N random non-equilibrium conformations 
are  generated  by  randomly  perturbing  the  molecule  along  the  normal  mode  coordinates.  For 
diverse normal mode sampling (DNMS), the atomic environment vector1  (referred to as AEV; a 
numerical vector used to describe the chemical environment of an atom in a molecule) for all C, 
N,  and  O  atoms  for  each  of  the  N  conformations  generated  with  NMS  is  stored.  The  squared 
Euclidean  distance  matrix  between  each  of  the  N  AEVs  is  computed.  Finally,  K  diverse 
conformers  is  selected  from  the  N  original  conformers  using  the  max-min  diversity  selector 
algorithm implemented in the RDKit [http://www.rdkit.org/] cheminformatics software package.  
For sampling, using the query by committee approach introduce in the main article we test all i 
conformers from the K selected diverse conformers. We generate QM energies and forces for all 
ùúå(cid:3036) >   ùúå(cid:3548)  (Section  IIA  of  the  main  article)  and  add  this  new  data  to  the  training  set  in  the  next 
iteration of the active learning algorithm. 
S1.2.2 K Random Trajectory Sampling (KRTS).  
Random trajectory sampling is carried out on a set of seed molecules from the conformational 
sampling  data  set.  Given  a  molecular  configuration,  a  random  set  of  Boltzmann  distributed 
velocities equal to 300K are generated. Molecular dynamics using the Langevin thermostat with 
0.25fs time step at 300K is then initialized. The system is heated linearly over 4ps to 1000K. Every 
5 steps of dynamics, ùúå(cid:3036) (Section IIA of the main article) is computed. If ùúå(cid:3036) >   ùúå(cid:3548) then dynamics is 
terminated.  DFT  reference  data  is  then  computed  for  the  final  conformation  and  added  to  the 
training set for the next iteration of the active learning cycle. If the trajectory reaches 4ps without 
encountering ùúå(cid:3036) >   ùúå(cid:3548) then no new data is added to the training set. Many trajectories can be run 
for each of the seed molecules back to back to generate multiple new reference data.  
S1.2.3 MD Generated Dimer Sampling 
Dimers are generated in an active learning scheme where a large box of hundreds of randomly 
selected  small  molecules  (from  the  conformational  sampling  set)  with  random  positions  and 
orientation is generated. Molecular dynamics at 300K with periodic boundary conditions using the 
current version of the ANI active learned potential is ran on the box of molecules for X ps. After 
the molecular dynamics run, the box is decomposed into all dimers with intermolecular distances 
less than 5.0√Ö. Query by committee (Section S1.1) is then performed on all generated dimers, 
selecting any dimer with ùúå(cid:3036) > ùúå(cid:3548). DFT reference calculations are performed for all selected dimers 
to obtain refence training data. The new reference training data is added to the training data set for 
the next iteration of the active learning cycle. X was initially chosen to be small (10fs) but after 
time the algorithm stops generating new dimers, thus X is increased iteratively. As of the ANI-1x 
data set X is set to 5ps. 
ùùà 
ùë¨ùëπ
ùùà  
ùë¨ùë¥
Table S1. Complete COMP6 benchmark suite results for various ANI potentials.  Errors for conformer 
energy differences (‚àÜE), potential energies (E), and force components (F) for the active learned ANI 
potentials ANI-AL1 to ANI-1X compared with the original ANI-1 potential. These results are from the 
combination of all benchmarks within the COMP6 benchmark suite. ¬µ and œÉ are the arithmetic mean 
and standard deviation, respectively. M and R are the MAE and RMSE, respectively. Units of energy 
are kcal  √ó mol(cid:2879)(cid:2869) and units of force are kcal  √ó mol(cid:2879)(cid:2869) √ó √Ö(cid:2879)(cid:2869). 
ùùÅ 
ùë¨ùëπ
21.10 
24.80 
13.43 
14.40 
3.58 
3.37 
16.94 
ANI 
Model 
AL1 
AL2 
AL3 
AL4 
AL5 
AL6 
ANI-1 
Table S2. DrugBank COMP6 benchmark results for various ANI potentials.  Errors for conformer 
energy differences (‚àÜE), potential energies (E), and force components (F) for the active learned ANI 
potentials ANI-AL1 to ANI-1X compared with the original ANI-1 potential. ¬µ and œÉ are the arithmetic 
mean and standard deviation, respectively. M and R are the MAE and RMSE, respectively. Units of 
energy are kcal  √ó mol(cid:2879)(cid:2869) and units of force are kcal  √ó mol(cid:2879)(cid:2869) √ó √Ö(cid:2879)(cid:2869). 
ùùà 
ùë¨ùëπ
ùùÅ  ‚àÜùë¨ùëπ
ùùà 
1.95 
1.88 
0.55 
0.30 
0.06 
0.15 
1.29 
ùùÅ   ‚àÜùë¨ùë¥
0.31 
0.47 
0.09 
0.09 
0.02 
0.04 
0.20 
ùùà   ‚àÜùë¨ùëπ
8.36 
6.42 
5.73 
5.32 
3.14 
2.95 
6.97 
ùùÅ 
ùë≠ùëπ
10.61 
9.72 
7.12 
6.89 
5.34 
5.29 
7.13 
ùùÅ  
ùë¨ùë¥
9.54 
10.21 
4.78 
5.04 
2.19 
1.93 
5.01 
‚àÜùë¨ùë¥
4.31 
3.56 
2.86 
2.72 
2.00 
1.85 
3.01 
ùùÅ  
ùë≠ùë¥
5.59 
5.19 
4.19 
4.01 
3.26 
3.09 
3.70 
1.36 
2.03 
0.24 
0.41 
0.24 
0.58 
1.36 
2.94 
6.52 
1.62 
1.79 
0.39 
0.78 
2.70 
0.21 
0.57 
0.09 
0.10 
0.04 
0.09 
0.15 
1.43 
1.46 
0.42 
0.50 
0.04 
0.08 
0.42 
ùùà  
ùë¨ùë¥
ùùà  
ùë≠ùë¥
ùùà  
ùë≠ùë¥
ùùà 
ùë≠ùëπ
ùùà 
ùë≠ùëπ
ANI 
Model 
AL1 
AL2 
AL3 
AL4 
AL5 
AL6 
ANI-1 
‚àÜùë¨ùë¥
4.69 
4.94 
3.49 
3.51 
2.17 
2.09 
3.41 
ùùÅ   ‚àÜùë¨ùë¥
0.47 
1.63 
0.22 
0.30 
0.08 
0.14 
0.13 
ùùà   ‚àÜùë¨ùëπ
6.69 
7.16 
4.89 
4.89 
3.05 
3.18 
4.94 
ùùÅ  ‚àÜùë¨ùëπ
ùùà 
0.90 
2.92 
0.29 
0.53 
0.66 
0.83 
0.42 
ùùÅ  
ùë¨ùë¥
29.08 
30.35 
12.99 
14.78 
2.79 
2.65 
13.89 
8.59 
8.71 
2.88 
2.23 
0.16 
0.28 
2.75 
ùùÅ 
ùë¨ùëπ
40.25 
42.80 
17.84 
19.33 
5.61 
6.01 
20.65 
11.15 
14.31 
3.47 
2.96 
1.92 
3.01 
3.07 
ùùÅ  
ùë≠ùë¥
5.90 
5.97 
4.58 
4.49 
2.99 
2.86 
4.04 
ùùÅ 
ùë≠ùëπ
10.70 
11.17 
7.78 
7.84 
4.83 
5.35 
7.62 
0.35 
1.47 
0.17 
0.34 
0.07 
0.16 
0.12 
1.01 
4.16 
0.38 
1.20 
1.08 
1.82 
1.55 
ùùÅ   ‚àÜùë¨ùë¥
Table S3. Tripeptide COMP6 benchmark.  Errors for conformer energy differences (‚àÜE), potential 
energies (E), and force components (F) for the active learned ANI potentials ANI-AL1 to ANI-1X 
compared with the original ANI-1 potential. ¬µ and œÉ are the arithmetic mean and standard deviation, 
respectively. M and R are the MAE and RMSE, respectively. Units of energy are kcal  √ó
mol(cid:2879)(cid:2869) and units of force are kcal  √ó mol(cid:2879)(cid:2869) √ó √Ö(cid:2879)(cid:2869). 
ANI 
Model  ‚àÜùë¨ùë¥
AL1 
4.75 
AL2 
4.08 
AL3 
3.54 
AL4 
2.92 
AL5 
1.78 
AL6 
1.65 
ANI-1 
2.86 
21.08 
27.82 
15.72 
15.35 
4.51 
3.77 
16.47 
11.45 
11.04 
9.18 
7.77 
4.43 
4.79 
6.67 
15.25 
20.92 
11.56 
13.17 
3.50 
2.92 
13.10 
13.79 
10.02 
8.75 
7.22 
2.90 
2.58 
4.99 
3.29 
4.70 
2.27 
3.33 
0.10 
0.22 
1.15 
0.36 
0.76 
0.10 
0.12 
0.05 
0.07 
0.31 
3.94 
7.78 
2.38 
3.00 
0.16 
0.47 
1.70 
4.79 
4.90 
4.26 
3.95 
2.67 
2.49 
3.46 
2.25 
1.50 
0.96 
1.07 
0.30 
0.48 
0.69 
0.21 
0.89 
0.14 
0.14 
0.05 
0.04 
0.34 
ùùÅ  ‚àÜùë¨ùëπ
ùùà 
ùùà   ‚àÜùë¨ùëπ
0.86 
1.87 
0.25 
0.73 
1.80 
0.70 
1.58 
ùùÅ  
ùë¨ùë¥
ùùÅ  
ùë≠ùë¥
ùùÅ 
ùë¨ùëπ
ùùÅ 
ùë≠ùëπ
ùùà  
ùë¨ùë¥
ùùà 
ùë≠ùëπ
ùùà 
ùë¨ùëπ
ùùà  
ùë≠ùë¥
Table S4. GDB07to09 COMP6 benchmark.  Errors for conformer energy differences (‚àÜE), potential 
energies (E), and force components (F) for the active learned ANI potentials ANI-AL1 to ANI-1X 
compared with the original ANI-1 potential. ¬µ and œÉ are the arithmetic mean and standard deviation, 
respectively. M and R are the MAE and RMSE, respectively. Units of energy are kcal  √ó
mol(cid:2879)(cid:2869) and units of force are kcal  √ó mol(cid:2879)(cid:2869) √ó √Ö(cid:2879)(cid:2869). 
ANI 
Model  ‚àÜùë¨ùë¥
AL1 
2.14 
AL2 
1.66 
AL3 
1.33 
AL4 
1.26 
AL5 
1.18 
AL6 
1.07 
ANI-1 
1.28 
ùùÅ  ‚àÜùë¨ùëπ
ùùà 
0.11 
0.13 
0.14 
0.05 
0.02 
0.05 
0.05 
ùùÅ   ‚àÜùë¨ùë¥
0.03 
0.03 
0.02 
0.01 
0.02 
0.03 
0.01 
ùùà   ‚àÜùë¨ùëπ
4.25 
2.83 
2.09 
1.92 
1.79 
1.66 
2.19 
ùùÅ  
ùë¨ùë¥
2.99 
2.82 
1.43 
1.34 
1.20 
1.04 
1.30 
ùùÅ  
ùë≠ùë¥
3.92 
3.39 
2.95 
2.81 
2.64 
2.43 
2.50 
ùùÅ 
ùë¨ùëπ
5.72 
5.53 
2.18 
1.89 
1.69 
1.50 
2.31 
ùùÅ 
ùë≠ùëπ
7.76 
6.35 
4.94 
4.59 
4.24 
3.93 
4.57 
0.03 
0.08 
0.03 
0.02 
0.04 
0.07 
0.03 
0.35 
0.34 
0.29 
0.06 
0.02 
0.05 
0.04 
0.12 
0.09 
0.02 
0.04 
0.02 
0.04 
0.01 
0.57 
0.42 
0.25 
0.06 
0.04 
0.08 
0.16 
ùùà  
ùë¨ùë¥
ùùà  
ùë≠ùë¥
ùùà 
ùë¨ùëπ
ùùà 
ùë≠ùëπ
Table S5. GDB10to13 COMP6 benchmark.  Errors for conformer energy differences (‚àÜE), potential 
energies (E), and force components (F) for the active learned ANI potentials ANI-AL1 to ANI-1X 
compared with the original ANI-1 potential. ¬µ and œÉ are the arithmetic mean and standard deviation, 
respectively. M and R are the MAE and RMSE, respectively. Units of energy are kcal  √ó
mol(cid:2879)(cid:2869) and units of force are kcal  √ó mol(cid:2879)(cid:2869) √ó √Ö(cid:2879)(cid:2869). 
ANI 
Model  ‚àÜùë¨ùë¥
AL1 
5.25 
AL2 
4.12 
AL3 
3.13 
AL4 
2.89 
AL5 
2.57 
AL6 
2.38 
ANI-1 
2.98 
ùùÅ 
ùùà   ‚àÜùë¨ùëπ
8.01 
6.25 
4.60 
4.19 
3.70 
3.47 
4.54 
ùùÅ   ‚àÜùë¨ùë¥
0.14 
0.24 
0.05 
0.04 
0.04 
0.05 
0.05 
ùùÅ 
ùë≠ùëπ
11.72 
10.03 
7.42 
7.03 
6.23 
6.01 
7.09 
ùùÅ 
ùë¨ùëπ
11.00 
13.43 
4.69 
4.48 
3.58 
3.21 
4.74 
ùùÅ  
ùë¨ùë¥
7.18 
7.70 
3.29 
3.32 
2.62 
2.30 
3.12 
ùùÅ  
ùë≠ùë¥
6.38 
5.65 
4.56 
4.31 
3.85 
3.67 
3.96 
0.43 
0.98 
0.10 
0.21 
0.05 
0.06 
0.11 
0.19 
0.39 
0.09 
0.06 
0.05 
0.09 
0.06 
0.60 
2.38 
0.25 
0.27 
0.05 
0.14 
0.24 
0.30 
0.52 
0.14 
0.08 
0.06 
0.11 
0.16 
0.69 
1.10 
0.26 
0.16 
0.08 
0.17 
0.24 
ùùà 
‚àÜùë¨ùëπ
ùùà  
ùë¨ùë¥
ùùà  
ùë≠ùë¥
ùùà 
ùë¨ùëπ
ùùà 
ùë≠ùëπ
Table S6. S66x8 COMP6 benchmark.  Errors for conformer energy differences (‚àÜE), potential energies 
(E), and force components (F) for the active learned ANI potentials ANI-AL1 to ANI-1X compared with 
the original ANI-1 potential. ¬µ and œÉ are the arithmetic mean and standard deviation, respectively. M 
and R are the MAE and RMSE, respectively. Units of energy are kcal  √ó
mol(cid:2879)(cid:2869) and units of force are kcal  √ó mol(cid:2879)(cid:2869) √ó √Ö(cid:2879)(cid:2869). 
ANI 
Model  ‚àÜùë¨ùë¥
AL1 
8.05 
AL2 
8.98 
AL3 
8.18 
AL4 
6.55 
AL5 
1.57 
AL6 
1.42 
ANI-1 
10.32 
ùùÅ 
ùùà   ‚àÜùë¨ùëπ
12.28 
13.77 
12.95 
10.85 
2.26 
2.10 
16.76 
ùùÅ   ‚àÜùë¨ùë¥
0.73 
1.40 
0.84 
0.29 
0.08 
0.09 
0.76 
ùùÅ 
ùë¨ùëπ
16.47 
17.09 
14.99 
12.71 
3.45 
3.01 
20.12 
ùùÅ  
ùë¨ùë¥
11.63 
11.95 
9.99 
8.54 
2.51 
2.06 
13.25 
ùùÅ  
ùë≠ùë¥
2.67 
2.63 
2.37 
2.41 
1.72 
1.60 
3.17 
ùùÅ 
ùë≠ùëπ
5.77 
5.87 
4.78 
4.54 
3.07 
2.76 
9.08 
0.12 
0.31 
0.14 
0.23 
0.06 
0.15 
0.36 
0.44 
2.47 
1.57 
0.74 
0.21 
0.18 
1.38 
0.34 
1.60 
1.01 
0.52 
0.17 
0.13 
0.96 
1.25 
2.37 
1.49 
0.71 
0.11 
0.26 
1.07 
0.21 
2.58 
0.82 
0.39 
0.17 
0.30 
4.07 
ùùà 
‚àÜùë¨ùëπ
ùùà  
ùë¨ùë¥
ùùà  
ùë≠ùë¥
ùùà 
ùë¨ùëπ
ùùà 
ùë≠ùëπ
Table S7. ANI-MD COMP6 benchmark.  Errors for conformer energy differences (‚àÜE), potential 
energies (E), and force components (F) for the active learned ANI potentials AL1 to AL6 compared 
with the original ANI-1 potential. ¬µ and œÉ are the arithmetic mean and standard deviation, 
respectively. M and R are the MAE and RMSE, respectively. Units of energy are kcal  √ó
mol(cid:2879)(cid:2869) and units of force are kcal  √ó mol(cid:2879)(cid:2869) √ó √Ö(cid:2879)(cid:2869). 
ANI 
Model  ‚àÜùë¨ùë¥
AL1 
8.47 
AL2 
7.15 
AL3 
6.80 
AL4 
6.61 
AL5 
2.82 
AL6 
2.59 
ANI-1 
8.93 
ùùÅ 
ùùà   ‚àÜùë¨ùëπ
17.11 
12.46 
13.43 
12.52 
4.61 
4.17 
18.08 
ùùÅ   ‚àÜùë¨ùë¥
2.34 
2.76 
0.76 
0.53 
0.09 
0.10 
1.58 
ùùÅ 
ùë¨ùëπ
92.95 
121.5 
82.56 
89.62 
8.10 
5.94 
109.2 
ùùÅ 
ùë≠ùëπ
11.11 
11.70 
8.11 
8.99 
4.47 
4.24 
12.70 
ùùÅ  
ùë¨ùë¥
51.55 
62.92 
41.41 
42.41 
4.39 
3.40 
52.30 
ùùà 
ùë¨ùëπ
12.64 
55.94 
13.44 
12.82 
1.88 
1.48 
25.32 
ùùà  
ùë¨ùë¥
6.19 
20.70 
5.10 
4.82 
0.73 
0.65 
8.84 
ùùà 
‚àÜùë¨ùëπ
7.89 
6.76 
2.33 
1.01 
0.28 
0.26 
4.39 
ùùÅ  
ùë≠ùë¥
5.95 
6.37 
4.99 
5.01 
2.89 
2.68 
5.80 
ùùà  
ùë≠ùë¥
1.47 
3.02 
0.37 
0.28 
0.06 
0.16 
1.61 
ùùà 
ùë≠ùëπ
10.58 
10.29 
1.17 
1.54 
0.10 
0.63 
7.80 
Table S8. Individual ANI-MD COMP6 benchmark trajectories.  Errors for conformer energy 
differences (‚àÜE), potential energies (E), and force components (F) for the ANI-1x potential vs DFT 
reference calculations on the 128 conformations per molecule in the ANI-MD COMP6 benchmark. 
Units of energy are kcal  √ó mol(cid:2879)(cid:2869) and units of force are kcal  √ó mol(cid:2879)(cid:2869) √ó √Ö(cid:2879)(cid:2869). Per conformation 
(conf.) energy and force prediction timings are also included for the ANI-1x potential. 
System 
Acetaminophen 
Caffeine 
Salbutamol 
Atomoxetine 
Lisdexamfetamine 
Capsaicin 
Oseltamivir 
Retinol 
Fentanyl 
Tolterodine 
Ranolazine 
Atazanavir 
Chignolin (1UAO) 
TrpCage (1L2Y) 
E 
MAE 
0.56 
0.98 
1.81 
1.19 
0.94 
1.53 
2.96 
3.68 
1.26 
1.91 
2.22 
2.73 
18.07 
16.34 
E 
RMSE 
0.70 
1.24 
2.10 
1.50 
1.18 
1.98 
3.45 
4.72 
1.58 
2.28 
2.62 
3.52 
18.47 
18.37 
E 
range 
15.7 
17.1 
21.2 
19.7 
27.9 
25.8 
40.7 
41.0 
29.8 
28.3 
29.1 
52.0 
45.5 
102.5 
F 
MAE 
2.06 
3.56 
2.16 
1.84 
1.63 
2.01 
2.41 
3.88 
2.03 
2.10 
2.20 
2.53 
3.25 
3.13 
F 
RMSE 
2.96 
5.46 
3.05 
2.62 
2.27 
2.91 
3.68 
7.70 
2.92 
3.04 
3.06 
3.80 
4.68 
4.59 
F 
range 
196.6 
260.1 
226.8 
203.0 
229.5 
231.1 
233.5 
285.6 
208.1 
205.1 
237.1 
242.9 
325.3 
249.7 
‚àÜE 
MAE 
0.80 
1.31 
1.23 
1.51 
1.29 
2.07 
1.95 
3.99 
1.69 
1.66 
1.95 
3.92 
4.36 
9.80 
‚àÜE 
RMSE 
1.00 
1.66 
1.55 
1.90 
1.66 
2.61 
2.57 
5.08 
2.13 
2.07 
2.45 
4.94 
5.42 
12.10 
‚àÜE 
range 
30.2 
34.1 
42.1 
36.5 
54.4 
50.3 
79.7 
75.5 
55.3 
54.4 
57.2 
101.1 
86.2 
191.0 
Time(ms) 
per conf. 
2.7 
3.0 
4.0 
4.3 
3.8 
3.6 
4.5 
4.0 
4.3 
5.3 
4.4 
5.0 
5.5 
9.3 
Table S9. Individual ANI-MD COMP6 benchmark trajectories per atom.  Per atom errors for the 
conformer energy differences (‚àÜùê∏) and potential energies (ùê∏) for the ANI-1x potential vs DFT 
reference calculations on the 128 conformations per molecule in the ANI-MD COMP6 benchmark. 
Units of energy are kcal  √ó mol(cid:2879)(cid:2869). 
System 
# of atoms 
Acetaminophen 
Caffeine 
Salbutamol 
Atomoxetine 
Lisdexamfetamine 
Capsaicin 
Oseltamivir 
Retinol 
Fentanyl 
Tolterodine 
Ranolazine 
Atazanavir 
Chignolin (1UAO) 
TrpCage (1L2Y) 
Mean 
20 
24 
38 
40 
44 
49 
50 
51 
53 
55 
64 
103 
149 
312 
75 
ùê∏(cid:3019)(cid:3014)(cid:3020)
‚àöùëÅ
0.16 
0.25 
0.34 
0.24 
0.18 
0.28 
0.49 
0.66 
0.22 
0.31 
0.33 
0.35 
1.51 
1.04 
0.45 
ùê∏(cid:3019)(cid:3014)(cid:3020)
0.04 
0.05 
0.06 
0.04 
0.03 
0.04 
0.07 
0.09 
0.03 
0.04 
0.04 
0.03 
0.12 
0.06 
0.05 
‚àÜùê∏(cid:3019)(cid:3014)(cid:3020)
‚àöùëÅ
0.22 
0.34 
0.25 
0.30 
0.25 
0.37 
0.36 
0.71 
0.29 
0.28 
0.31 
0.49 
0.44 
0.69 
0.38 
‚àÜùê∏(cid:3019)(cid:3014)(cid:3020)
0.05 
0.07 
0.04 
0.05 
0.04 
0.05 
0.05 
0.10 
0.04 
0.04 
0.04 
0.05 
0.04 
0.04 
0.05 
Table S10. Individual ANI-MD trajectories COMP6 benchmark for ANI, DFTB, and PM6.  ANI-1x, DFTB 
and PM6 vs DFT reference calculation errors for the conformer energy differences (‚àÜùê∏) and force 
components (F) on the 128 conformations per molecule in the ANI-MD COMP6 benchmark. Units of 
energy are kcal  √ó mol(cid:2879)(cid:2869) and units of force are kcal  √ó mol(cid:2879)(cid:2869) √ó √Ö(cid:2879)(cid:2869). 
ùêÉùêÖùêìùêÅ 
‚àÜùêÑùêåùêÄùêÑ
1.59 
4.63 
2.41 
2.33 
2.43 
5.50 
1.98 
2.27 
2.76 
4.01 
2.51 
2.46 
2.55 
9.84 
3.38 
ùêÉùêÖùêìùêÅ  ‚àÜùêÑùêëùêåùêí
ùêÄùêçùêà   ‚àÜùêÑùêëùêåùêí
ùêèùêåùüî 
2.00 
2.80 
9.27 
5.71 
3.85 
3.02 
6.08 
2.93 
3.02 
4.67 
12.1 
7.05 
4.76 
2.47 
5.29 
2.84 
4.94 
3.47 
4.97 
7.49 
3.85 
3.16 
4.46 
3.05 
4.36 
3.16 
12.3 
16.3 
6.45 
4.23 
ùêÄùêçùêà  
‚àÜùêÑùêåùêÄùêÑ
0.80 
3.92 
1.51 
1.31 
2.07 
4.36 
1.69 
1.29 
1.95 
1.95 
3.99 
1.23 
1.66 
9.80 
2.68 
ùêèùêåùüî 
‚àÜùêÑùêåùêÄùêÑ
2.23 
7.43 
3.12 
4.92 
3.76 
9.62 
3.81 
4.24 
4.00 
6.03 
3.05 
3.56 
3.44 
13.1 
5.16 
System 
Acetaminophen 
Atazanavir 
Atomoxetine 
Caffeine 
Capsaicin 
Chignolin (1UAO) 
Fentanyl 
Lisdexamfetamine 
Oseltamivir 
Ranolazine 
Retinol 
Salbutamol 
Tolterodine 
TrpCage (1L2Y) 
Mean 
ùêÄùêçùêà  
ùêÖùêåùêÄùêÑ
2.06 
2.53 
1.84 
3.56 
2.01 
3.25 
2.03 
1.63 
2.41 
2.20 
3.88 
2.16 
2.10 
3.13 
2.49 
ùêèùêåùüî 
ùêÖùêåùêÄùêÑ
7.23 
8.14 
6.38 
12.0 
6.72 
9.76 
6.71 
6.84 
7.31 
8.26 
5.21 
7.28 
5.92 
9.07 
7.63 
ùêÄùêçùêà  
ùêÖùêëùêåùêí
2.96 
3.80 
2.62 
5.46 
2.91 
4.68 
2.92 
2.27 
3.68 
3.06 
7.70 
3.05 
3.04 
4.59 
3.77 
‚àÜùêÑùêëùêåùêí
1.00 
4.94 
1.90 
1.66 
2.61 
5.42 
2.13 
1.66 
2.57 
2.45 
5.08 
1.55 
2.07 
12.1 
3.37 
ùêÉùêÖùêìùêÅ 
ùêÖùêåùêÄùêÑ
4.87 
5.11 
3.23 
7.30 
3.58 
5.87 
3.46 
3.53 
4.56 
4.20 
4.31 
4.20 
3.54 
5.38 
4.51 
ùêÉùêÖùêìùêÅ 
ùêÖùêëùêåùêí
7.16 
7.65 
4.57 
12.1 
5.33 
8.44 
5.12 
5.26 
6.79 
5.92 
6.99 
5.46 
4.89 
7.87 
6.68 
ùêèùêåùüî 
ùêÖùêëùêåùêí
10.8 
12.1 
9.25 
19.8 
9.86 
13.7 
9.60 
9.89 
10.4 
11.7 
7.16 
10.2 
8.29 
12.7 
11.1 
Table S11. ANI model details.  Model details on the individual active learned ANI models (ANI-AL) and 
a network ensemble trained to the original ANI-1 data set. AL version is an internal versioning scheme 
which allows tracking of the data included at any given model version. AL cycles are the number of 
active learning conformational search cycles completed to produce the given ANI-AL model. 
Parameters is the total number of parameters in the models, all of which consisted of an input size of 
386 and 3 total hidden layers with varying numbers of nodes per layer. Test set potential energy (E) 
RMSE are provided in kcal  √ó mol(cid:2879)(cid:2869). 
Model 
AL version 
AL Cycles 
Parameters 
AL1 
AL2 
AL3 
AL4 
AL5 
ANI-1X 
(AL6) 
ANI-1 
6.0.0 
6.2.4 
7.0.4 
8.0.5 
8.3.4 
9.0.5 
- 
0 
9 
13 
18 
32 
37 
- 
57472 
84096 
84096 
120000 
184512 
389376 
270592 
Test set 
RMSE (E) 
Configurational 
Sampling 
0.8 
1.1 
1.6 
2.2 
2.6 
2.7 
1.2 
GDB-1 to 6 
GDB-1 to 6 
GDB-1 to 7 
GDB-1 to 8 
GDB-1 to 8; GDB-1 to 6 dimers; amino acids; 
dipeptides; CheMBLE 
GDB-1 to 9; GDB-1 to 6 dimers; amino acids; 
dipeptides; CheMBLE 
GDB-1 to 8 
Table S12. Complete COMP6 benchmark for ANI-1x within select energy ranges.  Errors for 
conformer energy differences (‚àÜE), potential energies (E), and force components (F) for the active 
learned ANI potential ANI-1x over select energy ranges of the test set.  The test set for a given energy 
range is built by only considering conformations of a given molecule within the energy range (shown 
in column 2) from the minimum energy conformer in the set of conformations. These results are from 
the combination of all benchmarks within the COMP6 benchmark suite. ¬µ and œÉ are the arithmetic 
mean and standard deviation, respectively. M and R are the MAE and RMSE, respectively. Units of 
energy are kcal  √ó mol(cid:2879)(cid:2869) and units of force are kcal  √ó mol(cid:2879)(cid:2869) √ó √Ö(cid:2879)(cid:2869). 
ANI 
Model 
ùùÅ  
ùë≠ùë¥
ùùÅ 
ùë¨ùëπ
ùùà 
ùë¨ùëπ
ùùà  
ùë≠ùë¥
ùùÅ 
ùë≠ùëπ
ùùà 
ùë≠ùëπ
Energy 
Range  ‚àÜùë¨ùë¥
0.65 
1.05 
1.19 
1.39 
1.58 
1.71 
1.79 
1.82 
10 
30 
50 
100 
150 
200 
250 
300 
ùùÅ   ‚àÜùë¨ùë¥
0.01 
0.02 
0.03 
0.03 
0.04 
0.04 
0.04 
0.04 
ùùà   ‚àÜùë¨ùëπ
1.00 
1.65 
1.97 
2.28 
2.54 
2.73 
2.85 
2.91 
ùùÅ  ‚àÜùë¨ùëπ
0.05 
0.06 
0.08 
0.11 
0.13 
0.13 
0.15 
0.15 
ùùÅ   ùë¨ùë¥
ùùà  ùë¨ùë¥
ùùà  
0.06 
1.29 
0.06 
1.35 
1.44 
0.07 
0.07 
1.61 
0.08 
1.75 
1.84 
0.08 
0.08 
1.89 
1.91 
0.08 
ANI-1x 
2.60 
2.53 
2.71 
3.01 
3.19 
3.28 
3.33 
3.35 
0.93 
0.70 
0.81 
0.91 
0.88 
0.84 
0.81 
0.79 
2.21 
2.35 
2.48 
2.70 
2.87 
2.98 
3.04 
3.07 
0.08 
0.08 
0.08 
0.09 
0.09 
0.09 
0.10 
0.10 
3.68 
3.84 
4.11 
4.53 
4.85 
5.06 
5.18 
5.23 
0.49 
0.41 
0.56 
0.65 
0.64 
0.60 
0.58 
0.57 
Table S13. DrugBank COMP6 benchmark for ANI-1x within select energy ranges.  Errors for 
conformer energy differences (‚àÜE), potential energies (E), and force components (F) for the active 
learned ANI potential ANI-1x over select energy ranges of the test set. The test set for a given energy 
range is built by only considering conformations of a given molecule within the energy range (shown 
in column 2) from the minimum energy conformer in the set of conformations. ¬µ and œÉ are the 
arithmetic mean and standard deviation, respectively. M and R are the MAE and RMSE, respectively. 
Units of energy are kcal  √ó mol(cid:2879)(cid:2869) and units of force are kcal  √ó mol(cid:2879)(cid:2869) √ó √Ö(cid:2879)(cid:2869). 
ANI 
ùùÅ  
ùë≠ùë¥
Model 
ùùÅ 
ùë¨ùëπ
ùùÅ 
ùë≠ùëπ
ùùà  
ùë≠ùë¥
ùùà 
ùë¨ùëπ
ùùà 
ùë≠ùëπ
Energy 
Range  ‚àÜùë¨ùë¥
0.70 
0.92 
1.16 
1.58 
1.83 
1.97 
2.04 
2.07 
10 
30 
50 
100 
150 
200 
250 
300 
ùùÅ   ‚àÜùë¨ùë¥
0.10 
0.08 
0.13 
0.13 
0.14 
0.14 
0.14 
0.14 
ùùà   ‚àÜùë¨ùëπ
1.33 
1.58 
2.08 
2.61 
2.89 
3.04 
3.11 
3.15 
ùùÅ  ‚àÜùë¨ùëπ
0.67 
0.66 
1.02 
1.05 
1.00 
0.92 
0.87 
0.85 
ùùÅ   ùë¨ùë¥
ùùà  ùë¨ùë¥
ùùà  
0.36 
2.22 
0.27 
2.11 
2.22 
0.31 
0.31 
2.38 
0.30 
2.51 
2.59 
0.29 
0.28 
2.62 
2.64 
0.28 
ANI-1x 
6.83 
5.82 
6.06 
6.15 
6.12 
6.05 
6.02 
6.01 
4.25 
3.37 
3.57 
3.45 
3.28 
3.13 
3.05 
3.02 
2.30 
2.36 
2.48 
2.66 
2.77 
2.82 
2.85 
2.86 
0.19 
0.16 
0.18 
0.18 
0.17 
0.17 
0.16 
0.16 
4.75 
4.73 
5.20 
5.37 
5.35 
5.37 
5.36 
5.35 
1.98 
1.74 
2.23 
2.24 
2.09 
1.95 
1.87 
1.84 
Table S14. Tripeptide COMP6 benchmark for ANI-1x within select energy ranges.  Errors for 
conformer energy differences (‚àÜE), potential energies (E), and force components (F) for the active 
learned ANI potential ANI-1x over select energy ranges of the test set. The test set for a given energy 
range is built by only considering conformations of a given molecule within the energy range (shown 
in column 2) from the minimum energy conformer in the set of conformations. ¬µ and œÉ are the 
arithmetic mean and standard deviation, respectively. M and R are the MAE and RMSE, respectively. 
Units of energy are kcal  √ó mol(cid:2879)(cid:2869) and units of force are kcal  √ó mol(cid:2879)(cid:2869) √ó √Ö(cid:2879)(cid:2869). 
ANI 
ùùÅ  
ùë≠ùë¥
Model 
ùùÅ 
ùë¨ùëπ
ùùÅ 
ùë≠ùëπ
ùùà  
ùë≠ùë¥
ùùà 
ùë¨ùëπ
ùùà 
ùë≠ùëπ
Energy 
Range  ‚àÜùë¨ùë¥
0.64 
0.90 
1.07 
1.35 
1.48 
1.53 
1.56 
1.59 
10 
30 
50 
100 
150 
200 
250 
300 
ùùÅ   ‚àÜùë¨ùë¥
0.03 
0.02 
0.02 
0.02 
0.04 
0.05 
0.05 
0.05 
ùùà   ‚àÜùë¨ùëπ
0.91 
1.20 
1.43 
1.80 
2.00 
2.09 
2.19 
2.34 
ùùÅ  ‚àÜùë¨ùëπ
0.05 
0.03 
0.04 
0.04 
0.07 
0.10 
0.11 
0.11 
ùùÅ   ùë¨ùë¥
ùùà  ùë¨ùë¥
ùùà  
0.24 
2.48 
2.59 
0.25 
0.23 
2.67 
0.20 
2.75 
0.19 
2.81 
2.84 
0.19 
0.19 
2.86 
2.88 
0.19 
ANI-1x 
3.05 
3.20 
3.28 
3.38 
3.45 
3.51 
3.58 
3.64 
0.25 
0.26 
0.24 
0.21 
0.18 
0.18 
0.19 
0.18 
2.12 
2.18 
2.25 
2.36 
2.41 
2.44 
2.45 
2.46 
0.04 
0.04 
0.04 
0.03 
0.04 
0.04 
0.04 
0.04 
3.16 
3.24 
3.33 
3.53 
3.72 
3.87 
3.98 
4.21 
0.06 
0.06 
0.06 
0.06 
0.09 
0.17 
0.18 
0.28 
Table S15. GDB07to09 COMP6 benchmark for ANI-1x within select energy ranges.  Errors for 
conformer energy differences (‚àÜE), potential energies (E), and force components (F) for the active 
learned ANI potential ANI-1x over select energy ranges of the test set. The test set for a given energy 
range is built by only considering conformations of a given molecule within the energy range (shown 
in column 2) from the minimum energy conformer in the set of conformations. ¬µ and œÉ are the 
arithmetic mean and standard deviation, respectively. M and R are the MAE and RMSE, respectively. 
Units of energy are kcal  √ó mol(cid:2879)(cid:2869) and units of force are kcal  √ó mol(cid:2879)(cid:2869) √ó √Ö(cid:2879)(cid:2869). 
ANI 
ùùÅ  
ùë≠ùë¥
Model 
ùùÅ 
ùë¨ùëπ
ùùÅ 
ùë≠ùëπ
ùùà  
ùë≠ùë¥
ùùà 
ùë¨ùëπ
ùùà 
ùë≠ùëπ
Energy 
Range  ‚àÜùë¨ùë¥
0.46 
0.71 
0.84 
0.99 
1.05 
1.07 
1.07 
1.07 
10 
30 
50 
100 
150 
200 
250 
300 
ùùÅ   ‚àÜùë¨ùë¥
0.01 
0.02 
0.02 
0.03 
0.03 
0.03 
0.03 
0.03 
ùùà   ‚àÜùë¨ùëπ
0.62 
0.95 
1.15 
1.41 
1.58 
1.65 
1.66 
1.66 
ùùÅ  ‚àÜùë¨ùëπ
0.02 
0.02 
0.03 
0.04 
0.04 
0.05 
0.05 
0.05 
ùùÅ   ùë¨ùë¥
ùùà  ùë¨ùë¥
ùùà  
0.04 
0.80 
0.04 
0.88 
0.93 
0.04 
0.04 
1.00 
0.04 
1.03 
1.04 
0.04 
0.04 
1.04 
1.04 
0.04 
ANI-1x 
1.09 
1.18 
1.25 
1.37 
1.46 
1.49 
1.50 
1.50 
0.05 
0.05 
0.05 
0.05 
0.05 
0.05 
0.05 
0.05 
1.93 
2.12 
2.24 
2.37 
2.42 
2.43 
2.43 
2.43 
0.06 
0.06 
0.06 
0.07 
0.07 
0.07 
0.07 
0.07 
2.96 
3.22 
3.42 
3.71 
3.87 
3.92 
3.93 
3.93 
0.08 
0.09 
0.09 
0.10 
0.10 
0.08 
0.08 
0.08 
Table S16. GDB10to13 COMP6 benchmark for ANI-1x within select energy ranges.  Errors for 
conformer energy differences (‚àÜE), potential energies (E), and force components (F) for the active 
learned ANI potential ANI-1x over select energy ranges of the test set. The test set for a given energy 
range is built by only considering conformations of a given molecule within the energy range (shown 
in column 2) from the minimum energy conformer in the set of conformations. ¬µ and œÉ are the 
arithmetic mean and standard deviation, respectively. M and R are the MAE and RMSE, respectively. 
Units of energy are kcal  √ó mol(cid:2879)(cid:2869) and units of force are kcal  √ó mol(cid:2879)(cid:2869) √ó √Ö(cid:2879)(cid:2869). 
ANI 
ùùÅ  
ùë≠ùë¥
Model 
ùùÅ 
ùë¨ùëπ
ùùÅ 
ùë≠ùëπ
ùùà  
ùë≠ùë¥
ùùà 
ùë¨ùëπ
ùùà 
ùë≠ùëπ
Energy 
Range  ‚àÜùë¨ùë¥
0.61 
0.90 
1.09 
1.47 
1.86 
2.13 
2.27 
2.34 
10 
30 
50 
100 
150 
200 
250 
300 
ùùÅ   ‚àÜùë¨ùë¥
0.01 
0.02 
0.02 
0.03 
0.04 
0.04 
0.05 
0.05 
ùùà   ‚àÜùë¨ùëπ
0.86 
1.24 
1.51 
2.12 
2.70 
3.09 
3.30 
3.40 
ùùÅ  ‚àÜùë¨ùëπ
0.02 
0.03 
0.03 
0.06 
0.06 
0.08 
0.11 
0.11 
ùùÅ   ùë¨ùë¥
ùùà  ùë¨ùë¥
ùùà  
0.03 
1.63 
1.66 
0.03 
0.03 
1.72 
0.04 
1.88 
0.05 
2.05 
2.18 
0.05 
0.05 
2.24 
2.27 
0.05 
ANI-1x 
2.18 
2.26 
2.34 
2.60 
2.85 
3.03 
3.13 
3.18 
0.04 
0.09 
0.08 
0.11 
0.10 
0.11 
0.14 
0.14 
2.48 
2.61 
2.75 
3.04 
3.32 
3.50 
3.60 
3.64 
0.07 
0.07 
0.07 
0.08 
0.08 
0.09 
0.09 
0.09 
3.94 
4.13 
4.34 
4.85 
5.35 
5.67 
5.87 
5.95 
0.12 
0.12 
0.12 
0.13 
0.14 
0.16 
0.17 
0.17 
Table S17. Complete COMP6 benchmark per atom errors for ANI-1x within select energy ranges.  Per 
atom errors for conformer energy differences (‚àÜE) and potential energies (E) achieved by the active 
learned ANI potential ANI-1x over select energy ranges of the entire COMP6 benchmark. The test set 
for a given energy range is built by only considering conformations of a given molecule within the 
energy range (shown in column 2) from the minimum energy conformer in the set of conformations. 
¬µ is the arithmetic mean. M and R are the MAE and RMSE, respectively. Units of energy are 
kcal  √ó mol(cid:2879)(cid:2869) per atom. 
ANI Model 
Energy Range 
ùùÅ  
ùë¨ùë¥
0.059 
0.061 
0.064 
0.070 
0.075 
0.077 
0.078 
0.079 
ùùÅ 
ùë¨ùëπ
0.101 
0.099 
0.105 
0.117 
0.125 
0.129 
0.130 
0.131 
ANI-1x 
10 
30 
50 
100 
150 
200 
250 
300 
ùùÅ  
‚àÜùë¨ùë¥
0.031 
0.042 
0.049 
0.059 
0.067 
0.072 
0.074 
0.075 
ùùÅ 
‚àÜùë¨ùëπ
0.044 
0.058 
0.070 
0.090 
0.107 
0.116 
0.120 
0.122 
Smith, J. S.; Isayev, O.; Roitberg, A. E. ANI-1: An Extensible Neural Network Potential with DFT 
Accuracy at Force Field Computational Cost. Chem. Sci. 2017, 27, 479‚Äì496. 
Kingma, D.; Ba, J. Adam: A Method for Stochastic Optimization. arXiv:1412.6980 [cs.LG] 2014, 1‚Äì
15. 
Brauer, B.; Kesharwani, M. K.; Kozuch, S.; Martin, J. M. L. The S66x8 Benchmark for Noncovalent 
Interactions Revisited: Explicitly Correlated Ab Initio Methods and Density Functional Theory. 
Phys. Chem. Chem. Phys. 2016, 18 (31), 20905‚Äì20925. 
(1)  
(2)  
(3)  
