— The need to predict or ﬁll-in missing data, often
referred to as matrix completion, is a common challenge in to-
day’s data-driven world. Previous strategies typically assume that
no structural difference between observed and missing entries
exists. Unfortunately, this assumption is woefully unrealistic in
many applications. For example, in the classic Netﬂix challenge,
in which one hopes to predict user-movie ratings for unseen
ﬁlms, the fact that the viewer has not watched a given movie
may indicate a lack of interest in that movie, thus suggesting
a lower rating than otherwise expected. We propose adjusting
the standard nuclear norm minimization strategy for matrix
completion to account for such structural differences between
observed and unobserved entries by regularizing the values of
the unobserved entries. We show that the proposed method
outperforms nuclear norm minimization in certain settings.
thus violating the assumption of uniform sampling of observed
entries across movies. On the ﬂip side, a missing entry may
indicate a user’s lack of interest in that particular movie.
Similarly, in sensor networks, entries may be missing because
of geographic limitations or missing connections; in survey
data, incomplete sections may be irrelevant or unimportant to
the user. In these settings, it is then reasonable to expect that
missing entries have lower values1 than observed entries.
In this work, we propose a modiﬁcation to the traditional
NNM for matrix completion that still results in a semi-deﬁnite
optimization problem, but also encourages lower values among
the unobserved entries. We show that this method works better
than NNM alone under certain sampling conditions.
I. 