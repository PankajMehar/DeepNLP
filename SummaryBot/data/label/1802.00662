Oneofthecoretaskinmulti-viewlearningistocaptureallrelationsamongviews.Forsequentialdata,therelationsnotonlyspanacrossviews,butalsoextendthroughouttheviewlengthtoformlong-termintra-viewandcross-viewinteractions.Inthispaper,wepresentanewmemoryaugmentedneuralnetworkmodelthataimstomodelthesecom-plexinteractionsbetweentwosequentialviewsthatareasynchronous.Ourmodelusestwoneuralencodersforreadingfromandwritingtotwoexternalmemoriesforencodinginputviews.Theintra-viewinteractionsandthelong-termdependenciesarecapturedbytheuseofmemoriesdur-ingthisencodingprocess.Therearetwomodesofmemoryaccessinginoursystem:late-fusionandearly-fusion,correspondingtolateandearlycross-viewinteractions.Inlate-fusionmode,thetwomemoriesaresep-arated,containingonlyview-speciﬁccontents.Intheearly-fusionmode,thetwomemoriessharethesameaddressingspace,allowingcross-memoryaccessing.Inbothcases,theknowledgefromthememoriesﬁnallywillbesynthesizedbyadecodertomakepredictionsovertheoutputspace.Theresultingdualmemoryneuralcomputerisdemonstratedonvariousofex-periments,fromthesyntheticsumoftwosequencestasktothetasksofdrugprescriptionanddiseaseprogressionsinhealthcare.Theresultsshowimprovedperformanceoverbothtraditionalalgorithmsanddeeplearningmethodsdesignedformulti-viewproblems.1