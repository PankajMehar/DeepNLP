{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import numpy as np\n",
    "tfe.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 10\n",
    "window_size = 3\n",
    "dict_size = 5\n",
    "filter_size = window_size*embed_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 0 0]\n",
      " [0 0 0]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0 0 0 1 3 1 3 2]\n",
      " [0 0 0 2 1 3 4 4]], shape=(2, 8), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#우선 Define by run을 위하여 데이터셋 강제생성\n",
    "\n",
    "ids = tf.constant([[1, 2, 3, 4, 3, 2, 1], [1, 2, 3, 2, 3, 2, 3]])\n",
    "label_ids = tf.constant([[0, 0, 0, 1, 3, 1, 3, 2], [0, 0, 0, 2, 1, 3, 4, 4]])\n",
    "init_label = label_ids[:, :window_size]\n",
    "label_legnth = int(label_ids.shape[1]) - window_size\n",
    "label_ids[: window_size:]\n",
    "\n",
    "\n",
    "print(init_label)\n",
    "print(label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1095, shape=(6,), dtype=int32, numpy=array([ 2,  1,  2, 10,  2, 20], dtype=int32)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#embedding lookup 보충\n",
    "\n",
    "param = tf.constant([10,20,30,40])\n",
    "ids = tf.constant([0,1,2,3])\n",
    "\n",
    "emb = tf.nn.embedding_lookup(param, ids)\n",
    "\n",
    "#arg can be list of tensors\n",
    "#mode에서는 index 0은 1st elem. of 1st tensor in the list. index 1은 1st elem.의  2번째 tensor.\n",
    "#index2 는 1st elem. 의 3번째 tensor... 등\n",
    "#index i는 1st element of (i+1)th tensor for all the index(0.. (n-1))\n",
    "\n",
    "params1 = tf.constant([1,2])\n",
    "params2 = tf.constant([10,20])\n",
    "ids = tf.constant([2,0,2,1,2,3])\n",
    "result = tf.nn.embedding_lookup([params1, params2], ids)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10)\n",
      "(2, 7)\n"
     ]
    }
   ],
   "source": [
    "embeddings = tfe.Variable(tf.truncated_normal([dict_size, embed_size]), trainable=False)\n",
    "input_embeds = tf.nn.embedding_lookup(embeddings, ids)\n",
    "\n",
    "# embedding\n",
    "input_embeds = tf.nn.embedding_lookup(embeddings, ids)\n",
    "input_flat = tf.layers.flatten(input_embeds)\n",
    "input_flat = tf.expand_dims(input_flat, -1)\n",
    "\n",
    "init_label = tf.nn.embedding_lookup(embeddings, init_label)\n",
    "init_label = tf.layers.flatten(init_label)\n",
    "init_label = tf.expand_dims(init_label, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 7, 10)\n",
      "(2, 70, 1)\n",
      "(2, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "#embedding\n",
    "print(embeddings.shape)\n",
    "print(ids.shape)\n",
    "\n",
    "print(input_embeds.shape)\n",
    "print(input_flat.shape)\n",
    "print(init_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(7), Dimension(20)])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_onehot = tf.one_hot(label_ids, depth=dict_size, dtype=tf.float32)\n",
    "\n",
    "encoder_conv = tf.layers.conv1d(\n",
    "        inputs=input_flat,\n",
    "        filters=2*embed_size,\n",
    "        kernel_size=filter_size,\n",
    "        strides=embed_size,\n",
    "        padding='same')\n",
    "\n",
    "encoder_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10)\n",
      "(2, 7)\n",
      "<__main__.Convs2s object at 0x7fd87015ceb8>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#fair seq\n",
    "class Convs2s(tfe.Network):\n",
    "    def __init(self):\n",
    "        super(Convs2s, self).__init__()\n",
    "        self.input_flat = self.track_layer(tf.layers.flatten(input_embeds))\n",
    "        self.input_flat = self.track_layer(tf.expand_dims(self.input_flat, -1))\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    def call(self, x):\n",
    "        result = self.input_flat(x)\n",
    "        result = self.layer2(result)\n",
    "        return result\n",
    "    \n",
    "model = Convs2s()\n",
    "print(Convs2s(ids))\n",
    "\n",
    "# embedding\n",
    "input_embeds = tf.nn.embedding_lookup(embeddings, features['ids'])\n",
    "\n",
    "input_flat = tf.layers.flatten(input_embeds)\n",
    "input_flat = tf.expand_dims(input_flat, -1)\n",
    "\n",
    "init_label = tf.nn.embedding_lookup(embeddings, features['init_label'])\n",
    "init_label = tf.layers.flatten(init_label)\n",
    "init_label = tf.expand_dims(init_label, -1)\n",
    "\n",
    "if not PREDICT:\n",
    "    label_onehot = tf.one_hot(labels, depth=dict_size, dtype=tf.float32)\n",
    "\n",
    "# encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 784)\n",
      "tf.Tensor([[[ 0.  0.  0.  0.  0.]]], shape=(1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "class MNISTModel(tfe.Network):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.layer1 = self.track_layer(tf.layers.Dense(units=5))\n",
    "        #self.layer2 = self.track_layer(tf.layers.Dense(units=10))\n",
    "    def call(self, input):\n",
    "        \"\"\"모델 실행\"\"\"\n",
    "        result = self.layer1(input)\n",
    "        #result = self.layer2(result)\n",
    "        return result\n",
    "    \n",
    "#placeholder나 session에 대한 기능이 없고, input을 pass되면 자동으로 세팅 됨\n",
    "\n",
    "# 테스트 데이터셋 생성하기\n",
    "model = MNISTModel()\n",
    "batch = tf.zeros([1, 1, 784])\n",
    "print(batch.shape)\n",
    "result = model(batch)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding\n",
    "input_embeds = tf.nn.embedding_lookup(embeddings, features['ids'])\n",
    "\n",
    "input_flat = tf.layers.flatten(input_embeds)\n",
    "input_flat = tf.expand_dims(input_flat, -1)\n",
    "\n",
    "init_label = tf.nn.embedding_lookup(embeddings, features['init_label'])\n",
    "init_label = tf.layers.flatten(init_label)\n",
    "init_label = tf.expand_dims(init_label, -1)\n",
    "\n",
    "if not PREDICT:\n",
    "    label_onehot = tf.one_hot(labels, depth=dict_size, dtype=tf.float32)\n",
    "\n",
    "# encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn():\n",
    "    ids = tf.constant([[5, 6, 10, 9, 2], [5, 6, 10, 60, 2]])\n",
    "    label_ids = tf.constant([[4, 22, 163, 649, 2], [4, 22, 163, 649, 2]])\n",
    "    return {'ids': ids,\n",
    "            'init_label': label_ids[:, :window_size],\n",
    "            'label_length': int(label_ids.shape[1])-window_size\n",
    "            }, label_ids[:, window_size:]\n",
    "\n",
    "input_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FATAL Flags parsing error: Unknown command line flag 'f'\n",
      "Pass --helpshort or --helpfull to see help on flags.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan/py3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def model_fn(mode, features, labels):\n",
    "    TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
    "    PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n",
    "\n",
    "    embeddings = tf.Variable(tf.truncated_normal([dict_size, embed_size]), trainable=False)\n",
    "\n",
    "    # embedding\n",
    "    input_embeds = tf.nn.embedding_lookup(embeddings, features['ids'])\n",
    "\n",
    "    input_flat = tf.layers.flatten(input_embeds)\n",
    "    input_flat = tf.expand_dims(input_flat, -1)\n",
    "\n",
    "    init_label = tf.nn.embedding_lookup(embeddings, features['init_label'])\n",
    "    init_label = tf.layers.flatten(init_label)\n",
    "    init_label = tf.expand_dims(init_label, -1)\n",
    "\n",
    "    if not PREDICT:\n",
    "        label_onehot = tf.one_hot(labels, depth=dict_size, dtype=tf.float32)\n",
    "\n",
    "    # encoder\n",
    "    encoder_conv = tf.layers.conv1d(\n",
    "            inputs=input_flat,\n",
    "            filters=2*embed_size,\n",
    "            kernel_size=filter_size,\n",
    "            strides=embed_size,\n",
    "            padding='same')\n",
    "\n",
    "    encoder_glu = encoder_conv[:, :, embed_size:]*tf.nn.sigmoid(encoder_conv[:, :, :embed_size])\n",
    "\n",
    "    #decoder\n",
    "    next_ids = []\n",
    "    outs = []\n",
    "    for l in range(features['label_length']):\n",
    "        if l == 0: decoder_input = init_label\n",
    "\n",
    "        decoder_conv = tf.layers.conv1d(\n",
    "                inputs=init_label,\n",
    "                filters=2*embed_size,\n",
    "                kernel_size=filter_size,\n",
    "                strides=embed_size)\n",
    "\n",
    "\n",
    "        decoder_glu = decoder_conv[:, :, embed_size:]*tf.nn.sigmoid(decoder_conv[:, :, :embed_size])\n",
    "\n",
    "        tiled_decoder_glu = tf.tile(decoder_glu, [1, int(encoder_glu.shape[1]), 1])\n",
    "\n",
    "\n",
    "        dot_prod = tf.matmul(encoder_glu, decoder_glu, transpose_b=True)\n",
    "\n",
    "        attention = tf.nn.softmax(dot_prod)\n",
    "\n",
    "        z_plus_e = encoder_glu + input_embeds\n",
    "\n",
    "        tiled_attention = tf.tile(attention, [1, 1, embed_size])\n",
    "\n",
    "        c = tf.reduce_sum(tiled_attention*z_plus_e, axis=1)\n",
    "        decoder_glu = tf.reshape(decoder_glu, [-1, embed_size])\n",
    "\n",
    "        logits = tf.layers.dense(c+decoder_glu, dict_size)\n",
    "\n",
    "        out = tf.nn.softmax(logits)\n",
    "\n",
    "        next_id = tf.argmax(out, axis=1)\n",
    "        next_embeds = tf.nn.embedding_lookup(embeddings, next_id)\n",
    "        next_embeds = tf.expand_dims(next_embeds, -1)\n",
    "        decoder_input = tf.concat([decoder_input[:, embed_size:], next_embeds], axis=1)\n",
    "\n",
    "        next_ids.append(next_id)\n",
    "        outs.append(logits)\n",
    "\n",
    "    outs = tf.stack(outs, axis=1)\n",
    "    next_ids = tf.stack(next_ids, axis=1)\n",
    "\n",
    "    if TRAIN:\n",
    "        global_step = tf.train.get_global_step()\n",
    "        loss = tf.losses.softmax_cross_entropy(label_onehot, outs)\n",
    "        train_op = tf.train.GradientDescentOptimizer(1e-2).minimize(loss, global_step)\n",
    "        estimator_spec = tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                train_op=train_op,\n",
    "                loss=loss)\n",
    "\n",
    "    elif EVAL:\n",
    "        loss = tf.losses.softmax_cross_entropy(label_onehot, outs)\n",
    "        eval_metric_ops = {'acc': tf.metrics.accuracy(labels, next_ids)}\n",
    "        estimator_spec = tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                loss=loss,\n",
    "                eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "    elif PREDICT:\n",
    "        estimator_spec = tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                predictions={'prediction': next_ids})\n",
    "\n",
    "    else:\n",
    "        raise Exception('estiamtor spec is invalid')\n",
    "\n",
    "    return estimator_spec\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    fairseq = tf.estimator.Estimator(model_fn)\n",
    "    fairseq.train(input_fn, steps=10000)\n",
    "    fairseq.evaluate(input_fn, steps=10)\n",
    "\n",
    "    pred = fairseq.predict(input_fn)\n",
    "    for p in pred:\n",
    "        print('prediction: {}'.format(p['prediction']))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
